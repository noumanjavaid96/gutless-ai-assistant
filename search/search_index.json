{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(\\w+)"},"docs":[{"location":"","text":"Renesis AI Assistant Documentation \u00b6 Welcome to the Renesis AI Assistant documentation. This intelligent AI-powered assistant is designed to enhance productivity and provide intelligent responses using advanced natural language processing and vector search capabilities. \ud83d\ude80 Quick Start Get up and running in minutes with our streamlined setup process. Get Started \u2699\ufe0f Configuration Customize your AI assistant with flexible configuration options. Configure \ud83d\udcd6 User Guide Learn how to effectively use all features and capabilities. Learn More Documentation Sections \u00b6 \ud83c\udfd7\ufe0f Architecture \ud83d\udd27 API Reference \ud83d\udd0d Troubleshooting \u2753 FAQ \ud83d\udcdd Contributing \ud83d\ude80 Deployment Key Features \u00b6 \ud83e\udde0 AI-Powered Intelligence Advanced GPT-4o integration for intelligent response synthesis and natural language understanding. \u2728 Enhanced \ud83d\udd0d Semantic Search Vector-powered search capabilities for finding the most relevant content with precision. \ud83d\ude80 Fast \ud83d\udcac Native Integration Seamless Slack bot integration with rich formatting and interactive components. \u2705 Ready \ud83d\udcc4 Content Processing Automated ingestion and processing of videos, PDFs, and various document formats. \ud83d\udd04 Automated Technology Stack \u00b6 \ud83d\udc0d Backend Python 3.8+ with modern async capabilities \ud83e\udd16 AI/ML OpenAI GPT-4o and Embeddings API \ud83d\uddc4\ufe0f Vector Database Pinecone for semantic search \ud83d\udcac Chat Platform Slack Bolt framework \ud83d\udcc4 Content Processing Whisper and PyMuPDF \ud83d\ude80 Deployment Docker and Cloud Ready Ready to get started? Choose your preferred way to begin with Renesis AI Assistant \ud83d\udce6 Installation \u2699\ufe0f Configuration \ud83d\ude80 Deployment Support \u00b6 For questions, issues, or contributions, please refer to our troubleshooting guide or check the FAQ .","title":"Home"},{"location":"#renesis-ai-assistant-documentation","text":"Welcome to the Renesis AI Assistant documentation. This intelligent AI-powered assistant is designed to enhance productivity and provide intelligent responses using advanced natural language processing and vector search capabilities. \ud83d\ude80","title":"Renesis AI Assistant Documentation"},{"location":"#documentation-sections","text":"\ud83c\udfd7\ufe0f Architecture \ud83d\udd27 API Reference \ud83d\udd0d Troubleshooting \u2753 FAQ \ud83d\udcdd Contributing \ud83d\ude80 Deployment","title":"Documentation Sections"},{"location":"#key-features","text":"\ud83e\udde0","title":"Key Features"},{"location":"#technology-stack","text":"","title":"Technology Stack"},{"location":"#support","text":"For questions, issues, or contributions, please refer to our troubleshooting guide or check the FAQ .","title":"Support"},{"location":"README_DOCS/","text":"Renesis AI Assistant Documentation \u00b6 This directory contains the complete documentation for the Renesis AI Assistant project. The documentation is built using modern web technologies with a sleek, responsive design. \ud83d\udcda Documentation Structure \u00b6 docs/ \u251c\u2500\u2500 index.md # Main documentation homepage \u251c\u2500\u2500 installation.md # Installation and setup guide \u251c\u2500\u2500 configuration.md # Configuration reference \u251c\u2500\u2500 usage.md # User guide and how-to \u251c\u2500\u2500 architecture.md # System architecture overview \u251c\u2500\u2500 api-reference.md # API documentation \u251c\u2500\u2500 troubleshooting.md # Common issues and solutions \u251c\u2500\u2500 faq.md # Frequently asked questions \u251c\u2500\u2500 contributing.md # Contributing guidelines \u251c\u2500\u2500 requirements.txt # Documentation dependencies \u251c\u2500\u2500 stylesheets/ \u2502 \u2514\u2500\u2500 extra.css # Custom CSS styles \u251c\u2500\u2500 javascripts/ \u2502 \u2514\u2500\u2500 mathjax.js # MathJax configuration \u2514\u2500\u2500 README.md # This file \ud83d\ude80 Quick Start \u00b6 Prerequisites \u00b6 Python 3.8 or higher pip package manager Local Development \u00b6 Install documentation dependencies : pip install -r docs/requirements.txt Start the development server : python -m http.server 8000 Open your browser and navigate to http://localhost:8000 Edit documentation - changes will be automatically reloaded Building for Production \u00b6 Build the static site : npm run build The built site will be in the site/ directory Deploy the contents of site/ to your web server \ud83d\udee0\ufe0f Development Workflow \u00b6 Making Changes \u00b6 Edit Markdown files in the docs/ directory Preview changes using the local development server Test the build using the build command Commit your changes following our contributing guidelines Adding New Pages \u00b6 Create a new Markdown file in the docs/ directory Add the page to navigation in the site configuration: nav : - Home : index.md - Your New Page : your-new-page.md Link to the page from other relevant documentation Styling and Customization \u00b6 Custom CSS : Edit docs/stylesheets/extra.css Custom JavaScript : Edit docs/javascripts/mathjax.js or add new files Theme configuration : Modify the site configuration \ud83d\udcdd Writing Guidelines \u00b6 Markdown Best Practices \u00b6 Use clear, descriptive headings Include a table of contents for long pages Use code blocks with language specification: def example_function (): return \"Hello, World!\" Add admonitions for important information: !!! note \"Important\" This is an important note. !!! warning \"Caution\" This requires careful attention. !!! tip \"Pro Tip\" This is a helpful tip. Content Structure \u00b6 Start with an overview of what the page covers Use numbered lists for step-by-step instructions Include examples for code and configuration Add cross-references to related documentation End with next steps or related resources Code Documentation \u00b6 Include complete examples that users can copy and run Explain parameters and return values Show error handling where appropriate Use consistent formatting for code blocks API Documentation \u00b6 Document all public methods and classes Include parameter types and descriptions Show example requests and responses Document error codes and messages \ud83c\udfa8 Styling Features \u00b6 Available Components \u00b6 Status Badges \u00b6 < span class = \"status-badge success\" > Success </ span > < span class = \"status-badge warning\" > Warning </ span > < span class = \"status-badge error\" > Error </ span > < span class = \"status-badge info\" > Info </ span > Feature Cards \u00b6 < div class = \"feature-grid\" > < div class = \"feature-card\" > < div class = \"icon\" > \ud83d\ude80 </ div > < h3 > Feature Title </ h3 > < p > Feature description goes here. </ p > </ div > </ div > Button Links \u00b6 < a href = \"/path/to/page\" class = \"button\" > Primary Button </ a > < a href = \"/path/to/page\" class = \"button secondary\" > Secondary Button </ a > API Method Documentation \u00b6 < div class = \"api-method\" > < div class = \"method-name\" > process_query </ div > < div class = \"method-signature\" > process_query(query: str, user_id: str) -> QueryResponse </ div > < p > Method description goes here. </ p > </ div > Mathematical Expressions \u00b6 MathJax is configured for mathematical notation: Inline math : \\(E = mc^2\\) Block math : \\[ \\text{similarity} = \\frac{\\vec{a} \\cdot \\vec{b}}{||\\vec{a}|| \\cdot ||\\vec{b}||} \\] Dark Mode Support \u00b6 The documentation automatically supports dark mode with: - Automatic theme detection - Manual theme toggle - Consistent styling across themes - Proper contrast ratios for accessibility \ud83d\udd27 Configuration \u00b6 Site Configuration \u00b6 The main configuration manages the site structure: site_name : Renesis AI Assistant Documentation theme : name : readthedocs features : - search - navigation Plugin Configuration \u00b6 Search : Enhanced search with highlighting Minify : Optimizes HTML, CSS, and JS Git info : Shows last modified dates Redirects : Handles URL redirects Extension Configuration \u00b6 PyMdown Extensions : Enhanced Markdown features Code highlighting : Syntax highlighting for code blocks Admonitions : Callout boxes for notes and warnings Tables : Enhanced table formatting Task lists : Checkbox lists Emoji : Emoji support \ud83d\ude80 Deployment \u00b6 GitHub Pages (Automatic) \u00b6 The documentation is automatically deployed to GitHub Pages when: - Changes are pushed to the main branch - Changes are made to documentation files - The GitHub Actions workflow completes successfully Manual Deployment \u00b6 Build the documentation : npm run build Deploy to GitHub Pages : npm run deploy Deploy to custom server : # Copy the site/ directory to your web server rsync -av site/ user@server:/path/to/webroot/ Docker Deployment \u00b6 FROM nginx:alpine COPY site/ /usr/share/nginx/html/ EXPOSE 80 # Build the documentation npm run build # Build Docker image docker build -t gutless-docs . # Run container docker run -p 8080 :80 gutless-docs \ud83e\uddea Testing \u00b6 Local Testing \u00b6 # Test build npm run build --strict # Test serve npm run serve --strict # Check for broken links pip install linkchecker linkchecker http://localhost:8000/ Automated Testing \u00b6 The GitHub Actions workflow includes: - Build testing : Ensures documentation builds without errors - Link checking : Validates internal and external links - Accessibility testing : Checks for accessibility issues - Performance testing : Runs Lighthouse audits - Spell checking : Validates spelling and grammar - Markdown linting : Ensures consistent formatting \ud83d\udcca Analytics and Monitoring \u00b6 Google Analytics \u00b6 To enable Google Analytics: Get a Google Analytics tracking ID Update site configuration : extra : analytics : provider : google property : G-XXXXXXXXXX Performance Monitoring \u00b6 Lighthouse CI : Automated performance audits Core Web Vitals : Monitoring user experience metrics Uptime monitoring : Server availability checks \ud83d\udd0d Search Configuration \u00b6 Search Features \u00b6 Full-text search : Searches all content Search highlighting : Highlights search terms Search suggestions : Provides search suggestions Keyboard shortcuts : S to focus search Search Optimization \u00b6 Use descriptive headings for better search results Include relevant keywords in content Structure content logically with proper hierarchy Use meta descriptions for pages \ud83c\udf10 Internationalization \u00b6 Adding Languages \u00b6 Create language-specific directories : docs/ \u251c\u2500\u2500 en/ \u2502 \u251c\u2500\u2500 index.md \u2502 \u2514\u2500\u2500 ... \u2514\u2500\u2500 es/ \u251c\u2500\u2500 index.md \u2514\u2500\u2500 ... Configure language selection in the site configuration Update navigation for each language Add language switcher to theme \ud83d\udd27 Troubleshooting \u00b6 Common Issues \u00b6 Build Errors \u00b6 # Clear cache and rebuild rm -rf site/ npm run build --clean Serve Issues \u00b6 # Check for port conflicts lsof -i :8000 # Use different port npm run serve -- --port 8001 Plugin Errors \u00b6 # Update dependencies pip install --upgrade -r docs/requirements.txt # Check plugin compatibility npm --version Getting Help \u00b6 Check the project documentation Review the styling guide Search project issues on GitHub Ask in project discussions \ud83d\udcc8 Best Practices \u00b6 Performance \u00b6 Optimize images before adding to documentation Use appropriate image formats (WebP, SVG when possible) Minimize external dependencies Enable compression in web server configuration Accessibility \u00b6 Use semantic HTML in custom components Provide alt text for images Ensure proper heading hierarchy Test with screen readers Maintain good color contrast SEO \u00b6 Use descriptive page titles Include meta descriptions Structure content with proper headings Use internal linking Optimize for relevant keywords Maintenance \u00b6 Regular dependency updates Monitor for broken links Review and update content regularly Archive outdated information Maintain consistent style and tone \ud83e\udd1d Contributing \u00b6 We welcome contributions to the documentation! Please see our Contributing Guide for detailed information on: How to contribute Style guidelines Review process Code of conduct Quick Contribution Steps \u00b6 Fork the repository Create a feature branch Make your changes Test locally Submit a pull request \ud83d\udcde Support \u00b6 For documentation-related questions: Create an issue in the GitHub repository Start a discussion in GitHub Discussions Contact the maintainers directly For general project support, see the main README . This documentation is continuously improved. Last updated: December 2024","title":"Renesis AI Assistant Documentation"},{"location":"README_DOCS/#renesis-ai-assistant-documentation","text":"This directory contains the complete documentation for the Renesis AI Assistant project. The documentation is built using modern web technologies with a sleek, responsive design.","title":"Renesis AI Assistant Documentation"},{"location":"README_DOCS/#documentation-structure","text":"docs/ \u251c\u2500\u2500 index.md # Main documentation homepage \u251c\u2500\u2500 installation.md # Installation and setup guide \u251c\u2500\u2500 configuration.md # Configuration reference \u251c\u2500\u2500 usage.md # User guide and how-to \u251c\u2500\u2500 architecture.md # System architecture overview \u251c\u2500\u2500 api-reference.md # API documentation \u251c\u2500\u2500 troubleshooting.md # Common issues and solutions \u251c\u2500\u2500 faq.md # Frequently asked questions \u251c\u2500\u2500 contributing.md # Contributing guidelines \u251c\u2500\u2500 requirements.txt # Documentation dependencies \u251c\u2500\u2500 stylesheets/ \u2502 \u2514\u2500\u2500 extra.css # Custom CSS styles \u251c\u2500\u2500 javascripts/ \u2502 \u2514\u2500\u2500 mathjax.js # MathJax configuration \u2514\u2500\u2500 README.md # This file","title":"\ud83d\udcda Documentation Structure"},{"location":"README_DOCS/#quick-start","text":"","title":"\ud83d\ude80 Quick Start"},{"location":"README_DOCS/#prerequisites","text":"Python 3.8 or higher pip package manager","title":"Prerequisites"},{"location":"README_DOCS/#local-development","text":"Install documentation dependencies : pip install -r docs/requirements.txt Start the development server : python -m http.server 8000 Open your browser and navigate to http://localhost:8000 Edit documentation - changes will be automatically reloaded","title":"Local Development"},{"location":"README_DOCS/#building-for-production","text":"Build the static site : npm run build The built site will be in the site/ directory Deploy the contents of site/ to your web server","title":"Building for Production"},{"location":"README_DOCS/#development-workflow","text":"","title":"\ud83d\udee0\ufe0f Development Workflow"},{"location":"README_DOCS/#making-changes","text":"Edit Markdown files in the docs/ directory Preview changes using the local development server Test the build using the build command Commit your changes following our contributing guidelines","title":"Making Changes"},{"location":"README_DOCS/#adding-new-pages","text":"Create a new Markdown file in the docs/ directory Add the page to navigation in the site configuration: nav : - Home : index.md - Your New Page : your-new-page.md Link to the page from other relevant documentation","title":"Adding New Pages"},{"location":"README_DOCS/#styling-and-customization","text":"Custom CSS : Edit docs/stylesheets/extra.css Custom JavaScript : Edit docs/javascripts/mathjax.js or add new files Theme configuration : Modify the site configuration","title":"Styling and Customization"},{"location":"README_DOCS/#writing-guidelines","text":"","title":"\ud83d\udcdd Writing Guidelines"},{"location":"README_DOCS/#markdown-best-practices","text":"Use clear, descriptive headings Include a table of contents for long pages Use code blocks with language specification: def example_function (): return \"Hello, World!\" Add admonitions for important information: !!! note \"Important\" This is an important note. !!! warning \"Caution\" This requires careful attention. !!! tip \"Pro Tip\" This is a helpful tip.","title":"Markdown Best Practices"},{"location":"README_DOCS/#content-structure","text":"Start with an overview of what the page covers Use numbered lists for step-by-step instructions Include examples for code and configuration Add cross-references to related documentation End with next steps or related resources","title":"Content Structure"},{"location":"README_DOCS/#code-documentation","text":"Include complete examples that users can copy and run Explain parameters and return values Show error handling where appropriate Use consistent formatting for code blocks","title":"Code Documentation"},{"location":"README_DOCS/#api-documentation","text":"Document all public methods and classes Include parameter types and descriptions Show example requests and responses Document error codes and messages","title":"API Documentation"},{"location":"README_DOCS/#styling-features","text":"","title":"\ud83c\udfa8 Styling Features"},{"location":"README_DOCS/#available-components","text":"","title":"Available Components"},{"location":"README_DOCS/#status-badges","text":"< span class = \"status-badge success\" > Success </ span > < span class = \"status-badge warning\" > Warning </ span > < span class = \"status-badge error\" > Error </ span > < span class = \"status-badge info\" > Info </ span >","title":"Status Badges"},{"location":"README_DOCS/#feature-cards","text":"< div class = \"feature-grid\" > < div class = \"feature-card\" > < div class = \"icon\" > \ud83d\ude80 </ div > < h3 > Feature Title </ h3 > < p > Feature description goes here. </ p > </ div > </ div >","title":"Feature Cards"},{"location":"README_DOCS/#button-links","text":"< a href = \"/path/to/page\" class = \"button\" > Primary Button </ a > < a href = \"/path/to/page\" class = \"button secondary\" > Secondary Button </ a >","title":"Button Links"},{"location":"README_DOCS/#api-method-documentation","text":"< div class = \"api-method\" > < div class = \"method-name\" > process_query </ div > < div class = \"method-signature\" > process_query(query: str, user_id: str) -> QueryResponse </ div > < p > Method description goes here. </ p > </ div >","title":"API Method Documentation"},{"location":"README_DOCS/#mathematical-expressions","text":"MathJax is configured for mathematical notation: Inline math : \\(E = mc^2\\) Block math : \\[ \\text{similarity} = \\frac{\\vec{a} \\cdot \\vec{b}}{||\\vec{a}|| \\cdot ||\\vec{b}||} \\]","title":"Mathematical Expressions"},{"location":"README_DOCS/#dark-mode-support","text":"The documentation automatically supports dark mode with: - Automatic theme detection - Manual theme toggle - Consistent styling across themes - Proper contrast ratios for accessibility","title":"Dark Mode Support"},{"location":"README_DOCS/#configuration","text":"","title":"\ud83d\udd27 Configuration"},{"location":"README_DOCS/#site-configuration","text":"The main configuration manages the site structure: site_name : Renesis AI Assistant Documentation theme : name : readthedocs features : - search - navigation","title":"Site Configuration"},{"location":"README_DOCS/#plugin-configuration","text":"Search : Enhanced search with highlighting Minify : Optimizes HTML, CSS, and JS Git info : Shows last modified dates Redirects : Handles URL redirects","title":"Plugin Configuration"},{"location":"README_DOCS/#extension-configuration","text":"PyMdown Extensions : Enhanced Markdown features Code highlighting : Syntax highlighting for code blocks Admonitions : Callout boxes for notes and warnings Tables : Enhanced table formatting Task lists : Checkbox lists Emoji : Emoji support","title":"Extension Configuration"},{"location":"README_DOCS/#deployment","text":"","title":"\ud83d\ude80 Deployment"},{"location":"README_DOCS/#github-pages-automatic","text":"The documentation is automatically deployed to GitHub Pages when: - Changes are pushed to the main branch - Changes are made to documentation files - The GitHub Actions workflow completes successfully","title":"GitHub Pages (Automatic)"},{"location":"README_DOCS/#manual-deployment","text":"Build the documentation : npm run build Deploy to GitHub Pages : npm run deploy Deploy to custom server : # Copy the site/ directory to your web server rsync -av site/ user@server:/path/to/webroot/","title":"Manual Deployment"},{"location":"README_DOCS/#docker-deployment","text":"FROM nginx:alpine COPY site/ /usr/share/nginx/html/ EXPOSE 80 # Build the documentation npm run build # Build Docker image docker build -t gutless-docs . # Run container docker run -p 8080 :80 gutless-docs","title":"Docker Deployment"},{"location":"README_DOCS/#testing","text":"","title":"\ud83e\uddea Testing"},{"location":"README_DOCS/#local-testing","text":"# Test build npm run build --strict # Test serve npm run serve --strict # Check for broken links pip install linkchecker linkchecker http://localhost:8000/","title":"Local Testing"},{"location":"README_DOCS/#automated-testing","text":"The GitHub Actions workflow includes: - Build testing : Ensures documentation builds without errors - Link checking : Validates internal and external links - Accessibility testing : Checks for accessibility issues - Performance testing : Runs Lighthouse audits - Spell checking : Validates spelling and grammar - Markdown linting : Ensures consistent formatting","title":"Automated Testing"},{"location":"README_DOCS/#analytics-and-monitoring","text":"","title":"\ud83d\udcca Analytics and Monitoring"},{"location":"README_DOCS/#google-analytics","text":"To enable Google Analytics: Get a Google Analytics tracking ID Update site configuration : extra : analytics : provider : google property : G-XXXXXXXXXX","title":"Google Analytics"},{"location":"README_DOCS/#performance-monitoring","text":"Lighthouse CI : Automated performance audits Core Web Vitals : Monitoring user experience metrics Uptime monitoring : Server availability checks","title":"Performance Monitoring"},{"location":"README_DOCS/#search-configuration","text":"","title":"\ud83d\udd0d Search Configuration"},{"location":"README_DOCS/#search-features","text":"Full-text search : Searches all content Search highlighting : Highlights search terms Search suggestions : Provides search suggestions Keyboard shortcuts : S to focus search","title":"Search Features"},{"location":"README_DOCS/#search-optimization","text":"Use descriptive headings for better search results Include relevant keywords in content Structure content logically with proper hierarchy Use meta descriptions for pages","title":"Search Optimization"},{"location":"README_DOCS/#internationalization","text":"","title":"\ud83c\udf10 Internationalization"},{"location":"README_DOCS/#adding-languages","text":"Create language-specific directories : docs/ \u251c\u2500\u2500 en/ \u2502 \u251c\u2500\u2500 index.md \u2502 \u2514\u2500\u2500 ... \u2514\u2500\u2500 es/ \u251c\u2500\u2500 index.md \u2514\u2500\u2500 ... Configure language selection in the site configuration Update navigation for each language Add language switcher to theme","title":"Adding Languages"},{"location":"README_DOCS/#troubleshooting","text":"","title":"\ud83d\udd27 Troubleshooting"},{"location":"README_DOCS/#common-issues","text":"","title":"Common Issues"},{"location":"README_DOCS/#build-errors","text":"# Clear cache and rebuild rm -rf site/ npm run build --clean","title":"Build Errors"},{"location":"README_DOCS/#serve-issues","text":"# Check for port conflicts lsof -i :8000 # Use different port npm run serve -- --port 8001","title":"Serve Issues"},{"location":"README_DOCS/#plugin-errors","text":"# Update dependencies pip install --upgrade -r docs/requirements.txt # Check plugin compatibility npm --version","title":"Plugin Errors"},{"location":"README_DOCS/#getting-help","text":"Check the project documentation Review the styling guide Search project issues on GitHub Ask in project discussions","title":"Getting Help"},{"location":"README_DOCS/#best-practices","text":"","title":"\ud83d\udcc8 Best Practices"},{"location":"README_DOCS/#performance","text":"Optimize images before adding to documentation Use appropriate image formats (WebP, SVG when possible) Minimize external dependencies Enable compression in web server configuration","title":"Performance"},{"location":"README_DOCS/#accessibility","text":"Use semantic HTML in custom components Provide alt text for images Ensure proper heading hierarchy Test with screen readers Maintain good color contrast","title":"Accessibility"},{"location":"README_DOCS/#seo","text":"Use descriptive page titles Include meta descriptions Structure content with proper headings Use internal linking Optimize for relevant keywords","title":"SEO"},{"location":"README_DOCS/#maintenance","text":"Regular dependency updates Monitor for broken links Review and update content regularly Archive outdated information Maintain consistent style and tone","title":"Maintenance"},{"location":"README_DOCS/#contributing","text":"We welcome contributions to the documentation! Please see our Contributing Guide for detailed information on: How to contribute Style guidelines Review process Code of conduct","title":"\ud83e\udd1d Contributing"},{"location":"README_DOCS/#quick-contribution-steps","text":"Fork the repository Create a feature branch Make your changes Test locally Submit a pull request","title":"Quick Contribution Steps"},{"location":"README_DOCS/#support","text":"For documentation-related questions: Create an issue in the GitHub repository Start a discussion in GitHub Discussions Contact the maintainers directly For general project support, see the main README . This documentation is continuously improved. Last updated: December 2024","title":"\ud83d\udcde Support"},{"location":"api-reference/","text":"API Reference \u00b6 This document provides detailed API documentation for the Renesis AI Assistant's internal modules and external integrations. Core Modules \u00b6 Bot Interface ( src/bot.py ) \u00b6 SlackBot Class \u00b6 class SlackBot : \"\"\"Main Slack bot interface for handling user interactions.\"\"\" def __init__ ( self , token : str , signing_secret : str , app_token : str ) def start ( self ) -> None def handle_message ( self , message : dict ) -> None def handle_app_mention ( self , event : dict ) -> None def send_response ( self , channel : str , text : str , thread_ts : str = None ) -> None Methods: __init__(token, signing_secret, app_token) \u00b6 Initializes the Slack bot with required credentials. Parameters: - token (str): Slack bot token (xoxb-...) - signing_secret (str): Slack signing secret for request verification - app_token (str): Slack app token for Socket Mode (xapp-...) start() \u00b6 Starts the bot and begins listening for Slack events. Returns: None handle_message(message) \u00b6 Processes incoming direct messages. Parameters: - message (dict): Slack message event data Returns: None handle_app_mention(event) \u00b6 Processes messages where the bot is mentioned. Parameters: - event (dict): Slack app mention event data Returns: None send_response(channel, text, thread_ts=None) \u00b6 Sends a formatted response to Slack. Parameters: - channel (str): Slack channel ID - text (str): Response text (supports Slack markdown) - thread_ts (str, optional): Thread timestamp for threaded replies Returns: None Core Logic ( src/core_logic.py ) \u00b6 QueryProcessor Class \u00b6 class QueryProcessor : \"\"\"Orchestrates the query-to-answer pipeline.\"\"\" def __init__ ( self , embedding_service : EmbeddingService , pinecone_service : PineconeService ) def process_query ( self , query : str , user_id : str = None ) -> QueryResponse def preprocess_query ( self , query : str ) -> str def assemble_context ( self , search_results : List [ SearchResult ]) -> str def generate_answer ( self , query : str , context : str ) -> str def format_response ( self , answer : str , sources : List [ Source ]) -> QueryResponse Methods: process_query(query, user_id=None) \u00b6 Main method that processes a user query and returns a complete response. Parameters: - query (str): User's question - user_id (str, optional): Slack user ID for logging Returns: QueryResponse object Example: processor = QueryProcessor ( embedding_service , pinecone_service ) response = processor . process_query ( \"What foods should I avoid in Week 1?\" ) print ( response . answer ) print ( response . sources ) preprocess_query(query) \u00b6 Cleans and normalizes the user query. Parameters: - query (str): Raw user query Returns: str - Cleaned query assemble_context(search_results) \u00b6 Combines relevant search results into context for the LLM. Parameters: - search_results (List[SearchResult]): Results from vector search Returns: str - Assembled context generate_answer(query, context) \u00b6 Generates an answer using the LLM with the provided context. Parameters: - query (str): User's question - context (str): Relevant context from search results Returns: str - Generated answer format_response(answer, sources) \u00b6 Formats the final response with sources and metadata. Parameters: - answer (str): Generated answer - sources (List[Source]): Source references Returns: QueryResponse object Embedding Service ( src/embedding_service.py ) \u00b6 EmbeddingService Class \u00b6 class EmbeddingService : \"\"\"Handles text embedding generation using OpenAI.\"\"\" def __init__ ( self , api_key : str , model : str = \"text-embedding-ada-002\" ) def generate_embedding ( self , text : str ) -> List [ float ] def generate_embeddings_batch ( self , texts : List [ str ]) -> List [ List [ float ]] def get_embedding_dimension ( self ) -> int Methods: generate_embedding(text) \u00b6 Generates a single embedding for the provided text. Parameters: - text (str): Text to embed Returns: List[float] - 1536-dimensional embedding vector Example: embedding_service = EmbeddingService ( api_key ) vector = embedding_service . generate_embedding ( \"What is gut health?\" ) print ( len ( vector )) # 1536 generate_embeddings_batch(texts) \u00b6 Generates embeddings for multiple texts efficiently. Parameters: - texts (List[str]): List of texts to embed Returns: List[List[float]] - List of embedding vectors get_embedding_dimension() \u00b6 Returns the dimension of embeddings generated by the current model. Returns: int - Embedding dimension (1536 for text-embedding-ada-002) Pinecone Service ( src/pinecone_service.py ) \u00b6 PineconeService Class \u00b6 class PineconeService : \"\"\"Manages vector database operations with Pinecone.\"\"\" def __init__ ( self , api_key : str , environment : str , index_name : str ) def upsert_vectors ( self , vectors : List [ Vector ]) -> None def search ( self , query_vector : List [ float ], top_k : int = 5 , filter_dict : dict = None ) -> List [ SearchResult ] def delete_vectors ( self , ids : List [ str ]) -> None def get_index_stats ( self ) -> dict Methods: upsert_vectors(vectors) \u00b6 Inserts or updates vectors in the index. Parameters: - vectors (List[Vector]): List of Vector objects to upsert Returns: None Example: vectors = [ Vector ( id = \"chunk_1\" , values = embedding_vector , metadata = { \"source\" : \"week1_video.mp4\" , \"text\" : \"Content chunk text\" , \"timestamp_start\" : \"00:05:30\" } ) ] pinecone_service . upsert_vectors ( vectors ) search(query_vector, top_k=5, filter_dict=None) \u00b6 Searches for similar vectors in the index. Parameters: - query_vector (List[float]): Query embedding vector - top_k (int): Number of results to return - filter_dict (dict, optional): Metadata filters Returns: List[SearchResult] - Ranked search results Example: results = pinecone_service . search ( query_vector = query_embedding , top_k = 5 , filter_dict = { \"content_type\" : \"transcript\" } ) delete_vectors(ids) \u00b6 Deletes vectors from the index. Parameters: - ids (List[str]): List of vector IDs to delete Returns: None get_index_stats() \u00b6 Returns statistics about the index. Returns: dict - Index statistics Content Ingestion ( src/content_ingestion/ ) \u00b6 TranscriptionService Class \u00b6 class TranscriptionService : \"\"\"Handles audio/video transcription.\"\"\" def __init__ ( self , service_type : str = \"whisper\" ) def transcribe_file ( self , file_path : str ) -> TranscriptionResult def transcribe_url ( self , url : str ) -> TranscriptionResult def segment_transcript ( self , transcript : str , segment_length : int = 300 ) -> List [ TranscriptSegment ] PDFParser Class \u00b6 class PDFParser : \"\"\"Handles PDF content extraction.\"\"\" def __init__ ( self ) def extract_text ( self , file_path : str ) -> PDFContent def extract_with_metadata ( self , file_path : str ) -> PDFContent def chunk_content ( self , content : str , chunk_size : int = 1000 ) -> List [ ContentChunk ] ContentProcessor Class \u00b6 class ContentProcessor : \"\"\"Main content ingestion orchestrator.\"\"\" def __init__ ( self , transcription_service : TranscriptionService , pdf_parser : PDFParser , embedding_service : EmbeddingService , pinecone_service : PineconeService ) def process_video ( self , file_path : str , metadata : dict ) -> ProcessingResult def process_pdf ( self , file_path : str , metadata : dict ) -> ProcessingResult def process_batch ( self , file_list : List [ FileInfo ]) -> List [ ProcessingResult ] Data Models \u00b6 QueryResponse \u00b6 @dataclass class QueryResponse : \"\"\"Response object for processed queries.\"\"\" answer : str sources : List [ Source ] confidence : float processing_time : float metadata : dict SearchResult \u00b6 @dataclass class SearchResult : \"\"\"Result from vector similarity search.\"\"\" id : str score : float text : str metadata : dict Source \u00b6 @dataclass class Source : \"\"\"Source reference for answers.\"\"\" type : str # \"video\" or \"pdf\" name : str url : str timestamp : str = None # For videos page : int = None # For PDFs section : str = None Vector \u00b6 @dataclass class Vector : \"\"\"Vector object for Pinecone operations.\"\"\" id : str values : List [ float ] metadata : dict TranscriptionResult \u00b6 @dataclass class TranscriptionResult : \"\"\"Result from transcription service.\"\"\" text : str segments : List [ TranscriptSegment ] language : str confidence : float TranscriptSegment \u00b6 @dataclass class TranscriptSegment : \"\"\"Individual segment of transcribed content.\"\"\" text : str start_time : float end_time : float speaker : str = None PDFContent \u00b6 @dataclass class PDFContent : \"\"\"Extracted PDF content.\"\"\" text : str pages : List [ PageContent ] metadata : dict ContentChunk \u00b6 @dataclass class ContentChunk : \"\"\"Processed content chunk.\"\"\" text : str metadata : dict embedding : List [ float ] = None External API Integrations \u00b6 OpenAI API \u00b6 Embeddings Endpoint \u00b6 # Generate embeddings response = openai . Embedding . create ( model = \"text-embedding-ada-002\" , input = [ \"text to embed\" ] ) embedding = response [ 'data' ][ 0 ][ 'embedding' ] Chat Completions Endpoint \u00b6 # Generate chat completion response = openai . ChatCompletion . create ( model = \"gpt-4o\" , messages = [ { \"role\" : \"system\" , \"content\" : \"You are a helpful assistant.\" }, { \"role\" : \"user\" , \"content\" : \"User question with context\" } ], max_tokens = 1000 , temperature = 0.7 ) answer = response . choices [ 0 ] . message . content Pinecone API \u00b6 Index Operations \u00b6 # Initialize index index = pinecone . Index ( \"gutless-assistant\" ) # Upsert vectors index . upsert ( vectors = [ { \"id\" : \"chunk_1\" , \"values\" : embedding_vector , \"metadata\" : { \"source\" : \"video.mp4\" } } ]) # Query index results = index . query ( vector = query_vector , top_k = 5 , include_metadata = True ) Slack API \u00b6 Events API \u00b6 # Handle app mention event @app . event ( \"app_mention\" ) def handle_mention ( event , say ): user_query = extract_query ( event [ \"text\" ]) response = process_query ( user_query ) say ( response ) Web API \u00b6 # Send message client . chat_postMessage ( channel = channel_id , text = response_text , thread_ts = thread_timestamp ) Error Handling \u00b6 Custom Exceptions \u00b6 class GutlessAssistantError ( Exception ): \"\"\"Base exception for the application.\"\"\" pass class EmbeddingError ( GutlessAssistantError ): \"\"\"Error in embedding generation.\"\"\" pass class SearchError ( GutlessAssistantError ): \"\"\"Error in vector search.\"\"\" pass class TranscriptionError ( GutlessAssistantError ): \"\"\"Error in transcription process.\"\"\" pass Error Response Format \u00b6 @dataclass class ErrorResponse : \"\"\"Standardized error response.\"\"\" error_type : str message : str details : dict timestamp : datetime Rate Limiting \u00b6 OpenAI Rate Limits \u00b6 Embeddings: 3,000 requests/minute Chat Completions: 3,500 requests/minute Tokens per minute: 90,000 Pinecone Rate Limits \u00b6 Queries: 100 requests/second Upserts: 100 requests/second Slack Rate Limits \u00b6 Web API: 1+ requests/second (tier-based) Events API: No specific limit Authentication \u00b6 API Key Management \u00b6 # Environment variables OPENAI_API_KEY = os . getenv ( \"OPENAI_API_KEY\" ) PINECONE_API_KEY = os . getenv ( \"PINECONE_API_KEY\" ) SLACK_BOT_TOKEN = os . getenv ( \"SLACK_BOT_TOKEN\" ) Request Authentication \u00b6 # OpenAI openai . api_key = OPENAI_API_KEY # Pinecone pinecone . init ( api_key = PINECONE_API_KEY , environment = ENVIRONMENT ) # Slack app = App ( token = SLACK_BOT_TOKEN ) Next Steps \u00b6 Troubleshooting","title":"API Reference"},{"location":"api-reference/#api-reference","text":"This document provides detailed API documentation for the Renesis AI Assistant's internal modules and external integrations.","title":"API Reference"},{"location":"api-reference/#core-modules","text":"","title":"Core Modules"},{"location":"api-reference/#bot-interface-srcbotpy","text":"","title":"Bot Interface (src/bot.py)"},{"location":"api-reference/#slackbot-class","text":"class SlackBot : \"\"\"Main Slack bot interface for handling user interactions.\"\"\" def __init__ ( self , token : str , signing_secret : str , app_token : str ) def start ( self ) -> None def handle_message ( self , message : dict ) -> None def handle_app_mention ( self , event : dict ) -> None def send_response ( self , channel : str , text : str , thread_ts : str = None ) -> None Methods:","title":"SlackBot Class"},{"location":"api-reference/#__init__token-signing_secret-app_token","text":"Initializes the Slack bot with required credentials. Parameters: - token (str): Slack bot token (xoxb-...) - signing_secret (str): Slack signing secret for request verification - app_token (str): Slack app token for Socket Mode (xapp-...)","title":"__init__(token, signing_secret, app_token)"},{"location":"api-reference/#start","text":"Starts the bot and begins listening for Slack events. Returns: None","title":"start()"},{"location":"api-reference/#handle_messagemessage","text":"Processes incoming direct messages. Parameters: - message (dict): Slack message event data Returns: None","title":"handle_message(message)"},{"location":"api-reference/#handle_app_mentionevent","text":"Processes messages where the bot is mentioned. Parameters: - event (dict): Slack app mention event data Returns: None","title":"handle_app_mention(event)"},{"location":"api-reference/#send_responsechannel-text-thread_tsnone","text":"Sends a formatted response to Slack. Parameters: - channel (str): Slack channel ID - text (str): Response text (supports Slack markdown) - thread_ts (str, optional): Thread timestamp for threaded replies Returns: None","title":"send_response(channel, text, thread_ts=None)"},{"location":"api-reference/#core-logic-srccore_logicpy","text":"","title":"Core Logic (src/core_logic.py)"},{"location":"api-reference/#queryprocessor-class","text":"class QueryProcessor : \"\"\"Orchestrates the query-to-answer pipeline.\"\"\" def __init__ ( self , embedding_service : EmbeddingService , pinecone_service : PineconeService ) def process_query ( self , query : str , user_id : str = None ) -> QueryResponse def preprocess_query ( self , query : str ) -> str def assemble_context ( self , search_results : List [ SearchResult ]) -> str def generate_answer ( self , query : str , context : str ) -> str def format_response ( self , answer : str , sources : List [ Source ]) -> QueryResponse Methods:","title":"QueryProcessor Class"},{"location":"api-reference/#process_queryquery-user_idnone","text":"Main method that processes a user query and returns a complete response. Parameters: - query (str): User's question - user_id (str, optional): Slack user ID for logging Returns: QueryResponse object Example: processor = QueryProcessor ( embedding_service , pinecone_service ) response = processor . process_query ( \"What foods should I avoid in Week 1?\" ) print ( response . answer ) print ( response . sources )","title":"process_query(query, user_id=None)"},{"location":"api-reference/#preprocess_queryquery","text":"Cleans and normalizes the user query. Parameters: - query (str): Raw user query Returns: str - Cleaned query","title":"preprocess_query(query)"},{"location":"api-reference/#assemble_contextsearch_results","text":"Combines relevant search results into context for the LLM. Parameters: - search_results (List[SearchResult]): Results from vector search Returns: str - Assembled context","title":"assemble_context(search_results)"},{"location":"api-reference/#generate_answerquery-context","text":"Generates an answer using the LLM with the provided context. Parameters: - query (str): User's question - context (str): Relevant context from search results Returns: str - Generated answer","title":"generate_answer(query, context)"},{"location":"api-reference/#format_responseanswer-sources","text":"Formats the final response with sources and metadata. Parameters: - answer (str): Generated answer - sources (List[Source]): Source references Returns: QueryResponse object","title":"format_response(answer, sources)"},{"location":"api-reference/#embedding-service-srcembedding_servicepy","text":"","title":"Embedding Service (src/embedding_service.py)"},{"location":"api-reference/#embeddingservice-class","text":"class EmbeddingService : \"\"\"Handles text embedding generation using OpenAI.\"\"\" def __init__ ( self , api_key : str , model : str = \"text-embedding-ada-002\" ) def generate_embedding ( self , text : str ) -> List [ float ] def generate_embeddings_batch ( self , texts : List [ str ]) -> List [ List [ float ]] def get_embedding_dimension ( self ) -> int Methods:","title":"EmbeddingService Class"},{"location":"api-reference/#generate_embeddingtext","text":"Generates a single embedding for the provided text. Parameters: - text (str): Text to embed Returns: List[float] - 1536-dimensional embedding vector Example: embedding_service = EmbeddingService ( api_key ) vector = embedding_service . generate_embedding ( \"What is gut health?\" ) print ( len ( vector )) # 1536","title":"generate_embedding(text)"},{"location":"api-reference/#generate_embeddings_batchtexts","text":"Generates embeddings for multiple texts efficiently. Parameters: - texts (List[str]): List of texts to embed Returns: List[List[float]] - List of embedding vectors","title":"generate_embeddings_batch(texts)"},{"location":"api-reference/#get_embedding_dimension","text":"Returns the dimension of embeddings generated by the current model. Returns: int - Embedding dimension (1536 for text-embedding-ada-002)","title":"get_embedding_dimension()"},{"location":"api-reference/#pinecone-service-srcpinecone_servicepy","text":"","title":"Pinecone Service (src/pinecone_service.py)"},{"location":"api-reference/#pineconeservice-class","text":"class PineconeService : \"\"\"Manages vector database operations with Pinecone.\"\"\" def __init__ ( self , api_key : str , environment : str , index_name : str ) def upsert_vectors ( self , vectors : List [ Vector ]) -> None def search ( self , query_vector : List [ float ], top_k : int = 5 , filter_dict : dict = None ) -> List [ SearchResult ] def delete_vectors ( self , ids : List [ str ]) -> None def get_index_stats ( self ) -> dict Methods:","title":"PineconeService Class"},{"location":"api-reference/#upsert_vectorsvectors","text":"Inserts or updates vectors in the index. Parameters: - vectors (List[Vector]): List of Vector objects to upsert Returns: None Example: vectors = [ Vector ( id = \"chunk_1\" , values = embedding_vector , metadata = { \"source\" : \"week1_video.mp4\" , \"text\" : \"Content chunk text\" , \"timestamp_start\" : \"00:05:30\" } ) ] pinecone_service . upsert_vectors ( vectors )","title":"upsert_vectors(vectors)"},{"location":"api-reference/#searchquery_vector-top_k5-filter_dictnone","text":"Searches for similar vectors in the index. Parameters: - query_vector (List[float]): Query embedding vector - top_k (int): Number of results to return - filter_dict (dict, optional): Metadata filters Returns: List[SearchResult] - Ranked search results Example: results = pinecone_service . search ( query_vector = query_embedding , top_k = 5 , filter_dict = { \"content_type\" : \"transcript\" } )","title":"search(query_vector, top_k=5, filter_dict=None)"},{"location":"api-reference/#delete_vectorsids","text":"Deletes vectors from the index. Parameters: - ids (List[str]): List of vector IDs to delete Returns: None","title":"delete_vectors(ids)"},{"location":"api-reference/#get_index_stats","text":"Returns statistics about the index. Returns: dict - Index statistics","title":"get_index_stats()"},{"location":"api-reference/#content-ingestion-srccontent_ingestion","text":"","title":"Content Ingestion (src/content_ingestion/)"},{"location":"api-reference/#transcriptionservice-class","text":"class TranscriptionService : \"\"\"Handles audio/video transcription.\"\"\" def __init__ ( self , service_type : str = \"whisper\" ) def transcribe_file ( self , file_path : str ) -> TranscriptionResult def transcribe_url ( self , url : str ) -> TranscriptionResult def segment_transcript ( self , transcript : str , segment_length : int = 300 ) -> List [ TranscriptSegment ]","title":"TranscriptionService Class"},{"location":"api-reference/#pdfparser-class","text":"class PDFParser : \"\"\"Handles PDF content extraction.\"\"\" def __init__ ( self ) def extract_text ( self , file_path : str ) -> PDFContent def extract_with_metadata ( self , file_path : str ) -> PDFContent def chunk_content ( self , content : str , chunk_size : int = 1000 ) -> List [ ContentChunk ]","title":"PDFParser Class"},{"location":"api-reference/#contentprocessor-class","text":"class ContentProcessor : \"\"\"Main content ingestion orchestrator.\"\"\" def __init__ ( self , transcription_service : TranscriptionService , pdf_parser : PDFParser , embedding_service : EmbeddingService , pinecone_service : PineconeService ) def process_video ( self , file_path : str , metadata : dict ) -> ProcessingResult def process_pdf ( self , file_path : str , metadata : dict ) -> ProcessingResult def process_batch ( self , file_list : List [ FileInfo ]) -> List [ ProcessingResult ]","title":"ContentProcessor Class"},{"location":"api-reference/#data-models","text":"","title":"Data Models"},{"location":"api-reference/#queryresponse","text":"@dataclass class QueryResponse : \"\"\"Response object for processed queries.\"\"\" answer : str sources : List [ Source ] confidence : float processing_time : float metadata : dict","title":"QueryResponse"},{"location":"api-reference/#searchresult","text":"@dataclass class SearchResult : \"\"\"Result from vector similarity search.\"\"\" id : str score : float text : str metadata : dict","title":"SearchResult"},{"location":"api-reference/#source","text":"@dataclass class Source : \"\"\"Source reference for answers.\"\"\" type : str # \"video\" or \"pdf\" name : str url : str timestamp : str = None # For videos page : int = None # For PDFs section : str = None","title":"Source"},{"location":"api-reference/#vector","text":"@dataclass class Vector : \"\"\"Vector object for Pinecone operations.\"\"\" id : str values : List [ float ] metadata : dict","title":"Vector"},{"location":"api-reference/#transcriptionresult","text":"@dataclass class TranscriptionResult : \"\"\"Result from transcription service.\"\"\" text : str segments : List [ TranscriptSegment ] language : str confidence : float","title":"TranscriptionResult"},{"location":"api-reference/#transcriptsegment","text":"@dataclass class TranscriptSegment : \"\"\"Individual segment of transcribed content.\"\"\" text : str start_time : float end_time : float speaker : str = None","title":"TranscriptSegment"},{"location":"api-reference/#pdfcontent","text":"@dataclass class PDFContent : \"\"\"Extracted PDF content.\"\"\" text : str pages : List [ PageContent ] metadata : dict","title":"PDFContent"},{"location":"api-reference/#contentchunk","text":"@dataclass class ContentChunk : \"\"\"Processed content chunk.\"\"\" text : str metadata : dict embedding : List [ float ] = None","title":"ContentChunk"},{"location":"api-reference/#external-api-integrations","text":"","title":"External API Integrations"},{"location":"api-reference/#openai-api","text":"","title":"OpenAI API"},{"location":"api-reference/#embeddings-endpoint","text":"# Generate embeddings response = openai . Embedding . create ( model = \"text-embedding-ada-002\" , input = [ \"text to embed\" ] ) embedding = response [ 'data' ][ 0 ][ 'embedding' ]","title":"Embeddings Endpoint"},{"location":"api-reference/#chat-completions-endpoint","text":"# Generate chat completion response = openai . ChatCompletion . create ( model = \"gpt-4o\" , messages = [ { \"role\" : \"system\" , \"content\" : \"You are a helpful assistant.\" }, { \"role\" : \"user\" , \"content\" : \"User question with context\" } ], max_tokens = 1000 , temperature = 0.7 ) answer = response . choices [ 0 ] . message . content","title":"Chat Completions Endpoint"},{"location":"api-reference/#pinecone-api","text":"","title":"Pinecone API"},{"location":"api-reference/#index-operations","text":"# Initialize index index = pinecone . Index ( \"gutless-assistant\" ) # Upsert vectors index . upsert ( vectors = [ { \"id\" : \"chunk_1\" , \"values\" : embedding_vector , \"metadata\" : { \"source\" : \"video.mp4\" } } ]) # Query index results = index . query ( vector = query_vector , top_k = 5 , include_metadata = True )","title":"Index Operations"},{"location":"api-reference/#slack-api","text":"","title":"Slack API"},{"location":"api-reference/#events-api","text":"# Handle app mention event @app . event ( \"app_mention\" ) def handle_mention ( event , say ): user_query = extract_query ( event [ \"text\" ]) response = process_query ( user_query ) say ( response )","title":"Events API"},{"location":"api-reference/#web-api","text":"# Send message client . chat_postMessage ( channel = channel_id , text = response_text , thread_ts = thread_timestamp )","title":"Web API"},{"location":"api-reference/#error-handling","text":"","title":"Error Handling"},{"location":"api-reference/#custom-exceptions","text":"class GutlessAssistantError ( Exception ): \"\"\"Base exception for the application.\"\"\" pass class EmbeddingError ( GutlessAssistantError ): \"\"\"Error in embedding generation.\"\"\" pass class SearchError ( GutlessAssistantError ): \"\"\"Error in vector search.\"\"\" pass class TranscriptionError ( GutlessAssistantError ): \"\"\"Error in transcription process.\"\"\" pass","title":"Custom Exceptions"},{"location":"api-reference/#error-response-format","text":"@dataclass class ErrorResponse : \"\"\"Standardized error response.\"\"\" error_type : str message : str details : dict timestamp : datetime","title":"Error Response Format"},{"location":"api-reference/#rate-limiting","text":"","title":"Rate Limiting"},{"location":"api-reference/#openai-rate-limits","text":"Embeddings: 3,000 requests/minute Chat Completions: 3,500 requests/minute Tokens per minute: 90,000","title":"OpenAI Rate Limits"},{"location":"api-reference/#pinecone-rate-limits","text":"Queries: 100 requests/second Upserts: 100 requests/second","title":"Pinecone Rate Limits"},{"location":"api-reference/#slack-rate-limits","text":"Web API: 1+ requests/second (tier-based) Events API: No specific limit","title":"Slack Rate Limits"},{"location":"api-reference/#authentication","text":"","title":"Authentication"},{"location":"api-reference/#api-key-management","text":"# Environment variables OPENAI_API_KEY = os . getenv ( \"OPENAI_API_KEY\" ) PINECONE_API_KEY = os . getenv ( \"PINECONE_API_KEY\" ) SLACK_BOT_TOKEN = os . getenv ( \"SLACK_BOT_TOKEN\" )","title":"API Key Management"},{"location":"api-reference/#request-authentication","text":"# OpenAI openai . api_key = OPENAI_API_KEY # Pinecone pinecone . init ( api_key = PINECONE_API_KEY , environment = ENVIRONMENT ) # Slack app = App ( token = SLACK_BOT_TOKEN )","title":"Request Authentication"},{"location":"api-reference/#next-steps","text":"Troubleshooting","title":"Next Steps"},{"location":"architecture/","text":"System Architecture \u00b6 This document provides a comprehensive overview of the Renesis AI Assistant's architecture, including system components, data flow, and integration patterns. High-Level Architecture \u00b6 The Renesis AI Assistant follows a modular, event-driven architecture that processes user queries through multiple specialized layers. The system integrates Slack for user interaction, OpenAI for language processing, and Pinecone for vector-based content retrieval. Core Components \u00b6 1. Slack Bot Interface ( src/bot.py ) \u00b6 Purpose : Handles all Slack-related communications and user interactions. Responsibilities : - Receive messages from Slack Events API - Parse user queries and extract intent - Format and send responses back to Slack - Handle different message types (mentions, DMs, etc.) - Manage conversation context Key Technologies : - Slack Bolt SDK for Python - Socket Mode for development - Slack Web API for sending messages Integration Points : - Receives events from Slack Platform - Sends queries to Core Logic module - Formats responses for Slack display 2. Core Logic Orchestrator ( src/core_logic.py ) \u00b6 Purpose : Central coordinator that manages the query-to-answer pipeline. Responsibilities : - Process incoming user queries - Coordinate between different services - Implement the main business logic flow - Handle error scenarios and fallbacks - Manage response assembly Process Flow : 1. Receive query from Slack Bot 2. Preprocess and clean the query 3. Generate query embedding 4. Search for relevant content 5. Assemble context from search results 6. Generate answer using LLM 7. Format response with source references 8. Return structured response 3. Content Ingestion Pipeline ( src/content_ingestion/ ) \u00b6 Purpose : Processes raw content into searchable, embedded chunks. Components : 3.1 Transcription Service ( transcribe.py ) \u00b6 Converts audio/video to text using Whisper or AssemblyAI Handles multiple audio formats Preserves timestamp information Cleans and segments transcripts 3.2 PDF Parser ( pdf_parser.py ) \u00b6 Extracts text from PDF documents Preserves document structure Handles images and tables Maintains page and section references 3.3 Content Processor ( ingest.py ) \u00b6 Chunks content into manageable segments Adds metadata (source, timestamps, type) Generates embeddings for each chunk Stores processed content in vector database 4. Embedding Service ( src/embedding_service.py ) \u00b6 Purpose : Generates vector embeddings for text content and queries. Responsibilities : - Generate embeddings using OpenAI's text-embedding-ada-002 - Handle batch processing for efficiency - Manage embedding cache for performance - Normalize embeddings for consistent search Features : - Batch processing for multiple texts - Error handling and retry logic - Embedding dimension: 1536 - Cosine similarity optimization 5. Pinecone Service ( src/pinecone_service.py ) \u00b6 Purpose : Manages vector database operations for content storage and retrieval. Responsibilities : - Store content embeddings with metadata - Perform similarity searches - Manage index operations - Handle batch upserts and queries Index Schema : { \"id\" : \"unique_chunk_identifier\" , \"values\" : [ 1536- dime ns io nal vec t or ], \"metadata\" : { \"source\" : \"video_name_or_pdf_name\" , \"content_type\" : \"transcript|pdf\" , \"timestamp_start\" : \"00:05:30\" , \"timestamp_end\" : \"00:07:45\" , \"chunk_index\" : 0 , \"text\" : \"original_text_content\" , \"page_number\" : 3 , \"section\" : \"Introduction\" } } 6. Configuration Management ( config/settings.py ) \u00b6 Purpose : Centralized configuration management for all services. Features : - Environment-based configuration - Validation of required settings - Type conversion and defaults - Security best practices 7. Utilities ( src/utils/ ) \u00b6 Purpose : Shared utilities and helper functions. Components : - Logging configuration - Error handling utilities - Text processing helpers - Validation functions Data Flow \u00b6 Content Ingestion Flow \u00b6 The content ingestion pipeline transforms raw materials into searchable, embedded content through a systematic five-step process that preserves context and enables efficient retrieval. Query Processing Flow \u00b6 The query processing pipeline handles user requests through a nine-step process, from initial Slack input to final response delivery, with typical response times of 3-6 seconds depending on query complexity. Integration Patterns \u00b6 External Service Integration \u00b6 OpenAI API \u00b6 Embeddings : text-embedding-ada-002 model Chat Completion : GPT-4o model Rate Limiting : Implemented with exponential backoff Error Handling : Retry logic with circuit breaker pattern Pinecone Vector Database \u00b6 Connection : Persistent connection with connection pooling Indexing : Batch upserts for efficiency Querying : Optimized similarity search with metadata filtering Monitoring : Health checks and performance metrics Slack Platform \u00b6 Events API : Real-time message processing Web API : Response delivery Socket Mode : Development-friendly real-time connection Rate Limiting : Respect Slack's rate limits Internal Communication \u00b6 Service Layer Pattern \u00b6 Each major component is a service with defined interfaces Dependency injection for testability Clear separation of concerns Error propagation and handling Event-Driven Architecture \u00b6 Asynchronous processing where possible Event logging for debugging and monitoring Graceful degradation on service failures Security Architecture \u00b6 API Key Management \u00b6 Environment variable storage No hardcoded secrets Rotation capability Secure transmission (HTTPS/TLS) Data Protection \u00b6 Encryption in transit (HTTPS/TLS) Encryption at rest (Pinecone) Minimal data retention No PII storage Access Control \u00b6 Slack workspace-based access Bot permission scoping Rate limiting per user Input validation and sanitization Scalability Considerations \u00b6 Horizontal Scaling \u00b6 Stateless service design Load balancer compatibility Database connection pooling Caching strategies Performance Optimization \u00b6 Embedding caching Batch processing Asynchronous operations Connection reuse Monitoring & Observability \u00b6 Structured logging Performance metrics Error tracking Health checks Deployment Architecture \u00b6 The deployment architecture supports both development and production environments with different scaling and security considerations. Development uses local execution with Socket Mode, while production employs containerized deployment with load balancing and auto-scaling capabilities. Technology Stack Summary \u00b6 Component Technology Purpose Backend Python 3.8+ Core application logic Slack Integration Slack Bolt SDK Bot interface Vector Database Pinecone Similarity search LLM OpenAI GPT-4o Answer generation Embeddings OpenAI text-embedding-ada-002 Vector generation Transcription Whisper/AssemblyAI Audio to text PDF Processing PyMuPDF Document parsing Configuration python-dotenv Environment management Logging Python logging Observability Next Steps \u00b6 API Reference","title":"Architecture"},{"location":"architecture/#system-architecture","text":"This document provides a comprehensive overview of the Renesis AI Assistant's architecture, including system components, data flow, and integration patterns.","title":"System Architecture"},{"location":"architecture/#high-level-architecture","text":"The Renesis AI Assistant follows a modular, event-driven architecture that processes user queries through multiple specialized layers. The system integrates Slack for user interaction, OpenAI for language processing, and Pinecone for vector-based content retrieval.","title":"High-Level Architecture"},{"location":"architecture/#core-components","text":"","title":"Core Components"},{"location":"architecture/#1-slack-bot-interface-srcbotpy","text":"Purpose : Handles all Slack-related communications and user interactions. Responsibilities : - Receive messages from Slack Events API - Parse user queries and extract intent - Format and send responses back to Slack - Handle different message types (mentions, DMs, etc.) - Manage conversation context Key Technologies : - Slack Bolt SDK for Python - Socket Mode for development - Slack Web API for sending messages Integration Points : - Receives events from Slack Platform - Sends queries to Core Logic module - Formats responses for Slack display","title":"1. Slack Bot Interface (src/bot.py)"},{"location":"architecture/#2-core-logic-orchestrator-srccore_logicpy","text":"Purpose : Central coordinator that manages the query-to-answer pipeline. Responsibilities : - Process incoming user queries - Coordinate between different services - Implement the main business logic flow - Handle error scenarios and fallbacks - Manage response assembly Process Flow : 1. Receive query from Slack Bot 2. Preprocess and clean the query 3. Generate query embedding 4. Search for relevant content 5. Assemble context from search results 6. Generate answer using LLM 7. Format response with source references 8. Return structured response","title":"2. Core Logic Orchestrator (src/core_logic.py)"},{"location":"architecture/#3-content-ingestion-pipeline-srccontent_ingestion","text":"Purpose : Processes raw content into searchable, embedded chunks. Components :","title":"3. Content Ingestion Pipeline (src/content_ingestion/)"},{"location":"architecture/#31-transcription-service-transcribepy","text":"Converts audio/video to text using Whisper or AssemblyAI Handles multiple audio formats Preserves timestamp information Cleans and segments transcripts","title":"3.1 Transcription Service (transcribe.py)"},{"location":"architecture/#32-pdf-parser-pdf_parserpy","text":"Extracts text from PDF documents Preserves document structure Handles images and tables Maintains page and section references","title":"3.2 PDF Parser (pdf_parser.py)"},{"location":"architecture/#33-content-processor-ingestpy","text":"Chunks content into manageable segments Adds metadata (source, timestamps, type) Generates embeddings for each chunk Stores processed content in vector database","title":"3.3 Content Processor (ingest.py)"},{"location":"architecture/#4-embedding-service-srcembedding_servicepy","text":"Purpose : Generates vector embeddings for text content and queries. Responsibilities : - Generate embeddings using OpenAI's text-embedding-ada-002 - Handle batch processing for efficiency - Manage embedding cache for performance - Normalize embeddings for consistent search Features : - Batch processing for multiple texts - Error handling and retry logic - Embedding dimension: 1536 - Cosine similarity optimization","title":"4. Embedding Service (src/embedding_service.py)"},{"location":"architecture/#5-pinecone-service-srcpinecone_servicepy","text":"Purpose : Manages vector database operations for content storage and retrieval. Responsibilities : - Store content embeddings with metadata - Perform similarity searches - Manage index operations - Handle batch upserts and queries Index Schema : { \"id\" : \"unique_chunk_identifier\" , \"values\" : [ 1536- dime ns io nal vec t or ], \"metadata\" : { \"source\" : \"video_name_or_pdf_name\" , \"content_type\" : \"transcript|pdf\" , \"timestamp_start\" : \"00:05:30\" , \"timestamp_end\" : \"00:07:45\" , \"chunk_index\" : 0 , \"text\" : \"original_text_content\" , \"page_number\" : 3 , \"section\" : \"Introduction\" } }","title":"5. Pinecone Service (src/pinecone_service.py)"},{"location":"architecture/#6-configuration-management-configsettingspy","text":"Purpose : Centralized configuration management for all services. Features : - Environment-based configuration - Validation of required settings - Type conversion and defaults - Security best practices","title":"6. Configuration Management (config/settings.py)"},{"location":"architecture/#7-utilities-srcutils","text":"Purpose : Shared utilities and helper functions. Components : - Logging configuration - Error handling utilities - Text processing helpers - Validation functions","title":"7. Utilities (src/utils/)"},{"location":"architecture/#data-flow","text":"","title":"Data Flow"},{"location":"architecture/#content-ingestion-flow","text":"The content ingestion pipeline transforms raw materials into searchable, embedded content through a systematic five-step process that preserves context and enables efficient retrieval.","title":"Content Ingestion Flow"},{"location":"architecture/#query-processing-flow","text":"The query processing pipeline handles user requests through a nine-step process, from initial Slack input to final response delivery, with typical response times of 3-6 seconds depending on query complexity.","title":"Query Processing Flow"},{"location":"architecture/#integration-patterns","text":"","title":"Integration Patterns"},{"location":"architecture/#external-service-integration","text":"","title":"External Service Integration"},{"location":"architecture/#openai-api","text":"Embeddings : text-embedding-ada-002 model Chat Completion : GPT-4o model Rate Limiting : Implemented with exponential backoff Error Handling : Retry logic with circuit breaker pattern","title":"OpenAI API"},{"location":"architecture/#pinecone-vector-database","text":"Connection : Persistent connection with connection pooling Indexing : Batch upserts for efficiency Querying : Optimized similarity search with metadata filtering Monitoring : Health checks and performance metrics","title":"Pinecone Vector Database"},{"location":"architecture/#slack-platform","text":"Events API : Real-time message processing Web API : Response delivery Socket Mode : Development-friendly real-time connection Rate Limiting : Respect Slack's rate limits","title":"Slack Platform"},{"location":"architecture/#internal-communication","text":"","title":"Internal Communication"},{"location":"architecture/#service-layer-pattern","text":"Each major component is a service with defined interfaces Dependency injection for testability Clear separation of concerns Error propagation and handling","title":"Service Layer Pattern"},{"location":"architecture/#event-driven-architecture","text":"Asynchronous processing where possible Event logging for debugging and monitoring Graceful degradation on service failures","title":"Event-Driven Architecture"},{"location":"architecture/#security-architecture","text":"","title":"Security Architecture"},{"location":"architecture/#api-key-management","text":"Environment variable storage No hardcoded secrets Rotation capability Secure transmission (HTTPS/TLS)","title":"API Key Management"},{"location":"architecture/#data-protection","text":"Encryption in transit (HTTPS/TLS) Encryption at rest (Pinecone) Minimal data retention No PII storage","title":"Data Protection"},{"location":"architecture/#access-control","text":"Slack workspace-based access Bot permission scoping Rate limiting per user Input validation and sanitization","title":"Access Control"},{"location":"architecture/#scalability-considerations","text":"","title":"Scalability Considerations"},{"location":"architecture/#horizontal-scaling","text":"Stateless service design Load balancer compatibility Database connection pooling Caching strategies","title":"Horizontal Scaling"},{"location":"architecture/#performance-optimization","text":"Embedding caching Batch processing Asynchronous operations Connection reuse","title":"Performance Optimization"},{"location":"architecture/#monitoring-observability","text":"Structured logging Performance metrics Error tracking Health checks","title":"Monitoring &amp; Observability"},{"location":"architecture/#deployment-architecture","text":"The deployment architecture supports both development and production environments with different scaling and security considerations. Development uses local execution with Socket Mode, while production employs containerized deployment with load balancing and auto-scaling capabilities.","title":"Deployment Architecture"},{"location":"architecture/#technology-stack-summary","text":"Component Technology Purpose Backend Python 3.8+ Core application logic Slack Integration Slack Bolt SDK Bot interface Vector Database Pinecone Similarity search LLM OpenAI GPT-4o Answer generation Embeddings OpenAI text-embedding-ada-002 Vector generation Transcription Whisper/AssemblyAI Audio to text PDF Processing PyMuPDF Document parsing Configuration python-dotenv Environment management Logging Python logging Observability","title":"Technology Stack Summary"},{"location":"architecture/#next-steps","text":"API Reference","title":"Next Steps"},{"location":"configuration/","text":"Configuration Guide \u00b6 This guide covers all configuration options for the Renesis AI Assistant. Environment Variables \u00b6 The application uses environment variables for configuration. These should be set in a .env file in the project root. Required Configuration \u00b6 OpenAI Settings \u00b6 # OpenAI API key (required) OPENAI_API_KEY=sk-... # Model for answer generation (default: gpt-4o) OPENAI_MODEL=gpt-4o # Model for generating embeddings (default: text-embedding-ada-002) OPENAI_EMBEDDING_MODEL=text-embedding-ada-002 # Maximum tokens for responses (default: 1000) OPENAI_MAX_TOKENS=1000 # Temperature for response generation (default: 0.7) OPENAI_TEMPERATURE=0.7 Pinecone Settings \u00b6 # Pinecone API key (required) PINECONE_API_KEY=... # Pinecone environment (required) PINECONE_ENVIRONMENT=us-west1-gcp # Index name for storing embeddings (default: gutless-assistant) PINECONE_INDEX_NAME=gutless-assistant # Number of similar chunks to retrieve (default: 5) PINECONE_TOP_K=5 # Similarity threshold for results (default: 0.7) PINECONE_SCORE_THRESHOLD=0.7 Slack Settings \u00b6 # Slack bot token (required) SLACK_BOT_TOKEN=xoxb-... # Slack signing secret (required) SLACK_SIGNING_SECRET=... # Slack app token for Socket Mode (required for development) SLACK_APP_TOKEN=xapp-... # Port for Slack events (default: 3000) SLACK_PORT=3000 Optional Configuration \u00b6 Application Settings \u00b6 # Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL) LOG_LEVEL=INFO # Enable debug mode (True/False) DEBUG=False # Maximum content chunk size in characters (default: 1000) MAX_CHUNK_SIZE=1000 # Chunk overlap size in characters (default: 200) CHUNK_OVERLAP=200 Content Processing \u00b6 # Transcription service (whisper, assemblyai) TRANSCRIPTION_SERVICE=whisper # AssemblyAI API key (if using AssemblyAI) ASSEMBLYAI_API_KEY=... # Audio file formats to process SUPPORTED_AUDIO_FORMATS=mp3,wav,m4a,mp4 # PDF processing options PDF_EXTRACT_IMAGES=False PDF_EXTRACT_TABLES=True Configuration File \u00b6 Advanced configuration can be managed through config/settings.py : # config/settings.py import os from typing import List , Optional class Settings : # OpenAI Configuration OPENAI_API_KEY : str = os . getenv ( \"OPENAI_API_KEY\" ) OPENAI_MODEL : str = os . getenv ( \"OPENAI_MODEL\" , \"gpt-4o\" ) OPENAI_EMBEDDING_MODEL : str = os . getenv ( \"OPENAI_EMBEDDING_MODEL\" , \"text-embedding-ada-002\" ) OPENAI_MAX_TOKENS : int = int ( os . getenv ( \"OPENAI_MAX_TOKENS\" , \"1000\" )) OPENAI_TEMPERATURE : float = float ( os . getenv ( \"OPENAI_TEMPERATURE\" , \"0.7\" )) # Pinecone Configuration PINECONE_API_KEY : str = os . getenv ( \"PINECONE_API_KEY\" ) PINECONE_ENVIRONMENT : str = os . getenv ( \"PINECONE_ENVIRONMENT\" ) PINECONE_INDEX_NAME : str = os . getenv ( \"PINECONE_INDEX_NAME\" , \"gutless-assistant\" ) PINECONE_TOP_K : int = int ( os . getenv ( \"PINECONE_TOP_K\" , \"5\" )) PINECONE_SCORE_THRESHOLD : float = float ( os . getenv ( \"PINECONE_SCORE_THRESHOLD\" , \"0.7\" )) # Slack Configuration SLACK_BOT_TOKEN : str = os . getenv ( \"SLACK_BOT_TOKEN\" ) SLACK_SIGNING_SECRET : str = os . getenv ( \"SLACK_SIGNING_SECRET\" ) SLACK_APP_TOKEN : str = os . getenv ( \"SLACK_APP_TOKEN\" ) SLACK_PORT : int = int ( os . getenv ( \"SLACK_PORT\" , \"3000\" )) # Application Configuration LOG_LEVEL : str = os . getenv ( \"LOG_LEVEL\" , \"INFO\" ) DEBUG : bool = os . getenv ( \"DEBUG\" , \"False\" ) . lower () == \"true\" MAX_CHUNK_SIZE : int = int ( os . getenv ( \"MAX_CHUNK_SIZE\" , \"1000\" )) CHUNK_OVERLAP : int = int ( os . getenv ( \"CHUNK_OVERLAP\" , \"200\" )) # Content Processing TRANSCRIPTION_SERVICE : str = os . getenv ( \"TRANSCRIPTION_SERVICE\" , \"whisper\" ) ASSEMBLYAI_API_KEY : Optional [ str ] = os . getenv ( \"ASSEMBLYAI_API_KEY\" ) SUPPORTED_AUDIO_FORMATS : List [ str ] = os . getenv ( \"SUPPORTED_AUDIO_FORMATS\" , \"mp3,wav,m4a,mp4\" ) . split ( \",\" ) PDF_EXTRACT_IMAGES : bool = os . getenv ( \"PDF_EXTRACT_IMAGES\" , \"False\" ) . lower () == \"true\" PDF_EXTRACT_TABLES : bool = os . getenv ( \"PDF_EXTRACT_TABLES\" , \"True\" ) . lower () == \"true\" settings = Settings () Slack Bot Configuration \u00b6 Bot Permissions \u00b6 Ensure your Slack bot has the following OAuth scopes: app_mentions:read - Read messages that mention the bot chat:write - Send messages im:read - Read direct messages im:write - Send direct messages files:read - Read file information (if file upload support is needed) Event Subscriptions \u00b6 Configure the following events in your Slack app: app_mention - When the bot is mentioned message.im - Direct messages to the bot Socket Mode (Development) \u00b6 For development, enable Socket Mode in your Slack app settings. This allows the bot to receive events without exposing a public endpoint. Pinecone Index Configuration \u00b6 Index Settings \u00b6 When creating your Pinecone index, use these settings: { \"name\" : \"gutless-assistant\" , \"dimension\" : 1536 , \"metric\" : \"cosine\" , \"pods\" : 1 , \"replicas\" : 1 , \"pod_type\" : \"p1.x1\" } Metadata Schema \u00b6 The following metadata fields are stored with each vector: { \"source\" : \"video_name_or_pdf_name\" , \"content_type\" : \"transcript|pdf\" , \"timestamp_start\" : \"00:05:30\" , \"timestamp_end\" : \"00:07:45\" , \"chunk_index\" : 0 , \"text\" : \"original_text_content\" } Logging Configuration \u00b6 Logging is configured in src/utils/logging_config.py . You can customize: Log levels (DEBUG, INFO, WARNING, ERROR, CRITICAL) Log format Output destinations (console, file, external services) # Example logging configuration import logging logging . basicConfig ( level = logging . INFO , format = ' %(asctime)s - %(name)s - %(levelname)s - %(message)s ' , handlers = [ logging . StreamHandler (), logging . FileHandler ( 'logs/app.log' ) ] ) Security Considerations \u00b6 API Keys : Never commit API keys to version control Environment Files : Add .env to .gitignore Production : Use secure secret management in production Slack Tokens : Rotate tokens regularly Network : Use HTTPS for all external communications Validation \u00b6 To validate your configuration: # Test configuration python -c \"from config.settings import settings; print('Configuration loaded successfully')\" # Test API connections python scripts/test_connections.py Environment-Specific Configuration \u00b6 Development \u00b6 DEBUG=True LOG_LEVEL=DEBUG SLACK_PORT=3000 Production \u00b6 DEBUG=False LOG_LEVEL=INFO SLACK_PORT=80 Testing \u00b6 DEBUG=True LOG_LEVEL=DEBUG PINECONE_INDEX_NAME=gutless-assistant-test Next Steps \u00b6 Usage Guide Troubleshooting","title":"Configuration"},{"location":"configuration/#configuration-guide","text":"This guide covers all configuration options for the Renesis AI Assistant.","title":"Configuration Guide"},{"location":"configuration/#environment-variables","text":"The application uses environment variables for configuration. These should be set in a .env file in the project root.","title":"Environment Variables"},{"location":"configuration/#required-configuration","text":"","title":"Required Configuration"},{"location":"configuration/#openai-settings","text":"# OpenAI API key (required) OPENAI_API_KEY=sk-... # Model for answer generation (default: gpt-4o) OPENAI_MODEL=gpt-4o # Model for generating embeddings (default: text-embedding-ada-002) OPENAI_EMBEDDING_MODEL=text-embedding-ada-002 # Maximum tokens for responses (default: 1000) OPENAI_MAX_TOKENS=1000 # Temperature for response generation (default: 0.7) OPENAI_TEMPERATURE=0.7","title":"OpenAI Settings"},{"location":"configuration/#pinecone-settings","text":"# Pinecone API key (required) PINECONE_API_KEY=... # Pinecone environment (required) PINECONE_ENVIRONMENT=us-west1-gcp # Index name for storing embeddings (default: gutless-assistant) PINECONE_INDEX_NAME=gutless-assistant # Number of similar chunks to retrieve (default: 5) PINECONE_TOP_K=5 # Similarity threshold for results (default: 0.7) PINECONE_SCORE_THRESHOLD=0.7","title":"Pinecone Settings"},{"location":"configuration/#slack-settings","text":"# Slack bot token (required) SLACK_BOT_TOKEN=xoxb-... # Slack signing secret (required) SLACK_SIGNING_SECRET=... # Slack app token for Socket Mode (required for development) SLACK_APP_TOKEN=xapp-... # Port for Slack events (default: 3000) SLACK_PORT=3000","title":"Slack Settings"},{"location":"configuration/#optional-configuration","text":"","title":"Optional Configuration"},{"location":"configuration/#application-settings","text":"# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL) LOG_LEVEL=INFO # Enable debug mode (True/False) DEBUG=False # Maximum content chunk size in characters (default: 1000) MAX_CHUNK_SIZE=1000 # Chunk overlap size in characters (default: 200) CHUNK_OVERLAP=200","title":"Application Settings"},{"location":"configuration/#content-processing","text":"# Transcription service (whisper, assemblyai) TRANSCRIPTION_SERVICE=whisper # AssemblyAI API key (if using AssemblyAI) ASSEMBLYAI_API_KEY=... # Audio file formats to process SUPPORTED_AUDIO_FORMATS=mp3,wav,m4a,mp4 # PDF processing options PDF_EXTRACT_IMAGES=False PDF_EXTRACT_TABLES=True","title":"Content Processing"},{"location":"configuration/#configuration-file","text":"Advanced configuration can be managed through config/settings.py : # config/settings.py import os from typing import List , Optional class Settings : # OpenAI Configuration OPENAI_API_KEY : str = os . getenv ( \"OPENAI_API_KEY\" ) OPENAI_MODEL : str = os . getenv ( \"OPENAI_MODEL\" , \"gpt-4o\" ) OPENAI_EMBEDDING_MODEL : str = os . getenv ( \"OPENAI_EMBEDDING_MODEL\" , \"text-embedding-ada-002\" ) OPENAI_MAX_TOKENS : int = int ( os . getenv ( \"OPENAI_MAX_TOKENS\" , \"1000\" )) OPENAI_TEMPERATURE : float = float ( os . getenv ( \"OPENAI_TEMPERATURE\" , \"0.7\" )) # Pinecone Configuration PINECONE_API_KEY : str = os . getenv ( \"PINECONE_API_KEY\" ) PINECONE_ENVIRONMENT : str = os . getenv ( \"PINECONE_ENVIRONMENT\" ) PINECONE_INDEX_NAME : str = os . getenv ( \"PINECONE_INDEX_NAME\" , \"gutless-assistant\" ) PINECONE_TOP_K : int = int ( os . getenv ( \"PINECONE_TOP_K\" , \"5\" )) PINECONE_SCORE_THRESHOLD : float = float ( os . getenv ( \"PINECONE_SCORE_THRESHOLD\" , \"0.7\" )) # Slack Configuration SLACK_BOT_TOKEN : str = os . getenv ( \"SLACK_BOT_TOKEN\" ) SLACK_SIGNING_SECRET : str = os . getenv ( \"SLACK_SIGNING_SECRET\" ) SLACK_APP_TOKEN : str = os . getenv ( \"SLACK_APP_TOKEN\" ) SLACK_PORT : int = int ( os . getenv ( \"SLACK_PORT\" , \"3000\" )) # Application Configuration LOG_LEVEL : str = os . getenv ( \"LOG_LEVEL\" , \"INFO\" ) DEBUG : bool = os . getenv ( \"DEBUG\" , \"False\" ) . lower () == \"true\" MAX_CHUNK_SIZE : int = int ( os . getenv ( \"MAX_CHUNK_SIZE\" , \"1000\" )) CHUNK_OVERLAP : int = int ( os . getenv ( \"CHUNK_OVERLAP\" , \"200\" )) # Content Processing TRANSCRIPTION_SERVICE : str = os . getenv ( \"TRANSCRIPTION_SERVICE\" , \"whisper\" ) ASSEMBLYAI_API_KEY : Optional [ str ] = os . getenv ( \"ASSEMBLYAI_API_KEY\" ) SUPPORTED_AUDIO_FORMATS : List [ str ] = os . getenv ( \"SUPPORTED_AUDIO_FORMATS\" , \"mp3,wav,m4a,mp4\" ) . split ( \",\" ) PDF_EXTRACT_IMAGES : bool = os . getenv ( \"PDF_EXTRACT_IMAGES\" , \"False\" ) . lower () == \"true\" PDF_EXTRACT_TABLES : bool = os . getenv ( \"PDF_EXTRACT_TABLES\" , \"True\" ) . lower () == \"true\" settings = Settings ()","title":"Configuration File"},{"location":"configuration/#slack-bot-configuration","text":"","title":"Slack Bot Configuration"},{"location":"configuration/#bot-permissions","text":"Ensure your Slack bot has the following OAuth scopes: app_mentions:read - Read messages that mention the bot chat:write - Send messages im:read - Read direct messages im:write - Send direct messages files:read - Read file information (if file upload support is needed)","title":"Bot Permissions"},{"location":"configuration/#event-subscriptions","text":"Configure the following events in your Slack app: app_mention - When the bot is mentioned message.im - Direct messages to the bot","title":"Event Subscriptions"},{"location":"configuration/#socket-mode-development","text":"For development, enable Socket Mode in your Slack app settings. This allows the bot to receive events without exposing a public endpoint.","title":"Socket Mode (Development)"},{"location":"configuration/#pinecone-index-configuration","text":"","title":"Pinecone Index Configuration"},{"location":"configuration/#index-settings","text":"When creating your Pinecone index, use these settings: { \"name\" : \"gutless-assistant\" , \"dimension\" : 1536 , \"metric\" : \"cosine\" , \"pods\" : 1 , \"replicas\" : 1 , \"pod_type\" : \"p1.x1\" }","title":"Index Settings"},{"location":"configuration/#metadata-schema","text":"The following metadata fields are stored with each vector: { \"source\" : \"video_name_or_pdf_name\" , \"content_type\" : \"transcript|pdf\" , \"timestamp_start\" : \"00:05:30\" , \"timestamp_end\" : \"00:07:45\" , \"chunk_index\" : 0 , \"text\" : \"original_text_content\" }","title":"Metadata Schema"},{"location":"configuration/#logging-configuration","text":"Logging is configured in src/utils/logging_config.py . You can customize: Log levels (DEBUG, INFO, WARNING, ERROR, CRITICAL) Log format Output destinations (console, file, external services) # Example logging configuration import logging logging . basicConfig ( level = logging . INFO , format = ' %(asctime)s - %(name)s - %(levelname)s - %(message)s ' , handlers = [ logging . StreamHandler (), logging . FileHandler ( 'logs/app.log' ) ] )","title":"Logging Configuration"},{"location":"configuration/#security-considerations","text":"API Keys : Never commit API keys to version control Environment Files : Add .env to .gitignore Production : Use secure secret management in production Slack Tokens : Rotate tokens regularly Network : Use HTTPS for all external communications","title":"Security Considerations"},{"location":"configuration/#validation","text":"To validate your configuration: # Test configuration python -c \"from config.settings import settings; print('Configuration loaded successfully')\" # Test API connections python scripts/test_connections.py","title":"Validation"},{"location":"configuration/#environment-specific-configuration","text":"","title":"Environment-Specific Configuration"},{"location":"configuration/#development","text":"DEBUG=True LOG_LEVEL=DEBUG SLACK_PORT=3000","title":"Development"},{"location":"configuration/#production","text":"DEBUG=False LOG_LEVEL=INFO SLACK_PORT=80","title":"Production"},{"location":"configuration/#testing","text":"DEBUG=True LOG_LEVEL=DEBUG PINECONE_INDEX_NAME=gutless-assistant-test","title":"Testing"},{"location":"configuration/#next-steps","text":"Usage Guide Troubleshooting","title":"Next Steps"},{"location":"contributing/","text":"Contributing to Renesis AI Assistant \u00b6 Thank you for your interest in contributing to the Renesis AI Assistant! This guide will help you get started with contributing to the project. Table of Contents \u00b6 Code of Conduct Getting Started Development Setup Contributing Guidelines Pull Request Process Coding Standards Testing Documentation Issue Reporting Feature Requests Community Code of Conduct \u00b6 By participating in this project, you agree to abide by our Code of Conduct: Be respectful : Treat all contributors with respect and kindness Be inclusive : Welcome newcomers and help them get started Be constructive : Provide helpful feedback and suggestions Be professional : Maintain a professional tone in all communications Be patient : Remember that everyone has different skill levels and backgrounds Getting Started \u00b6 Prerequisites \u00b6 Before contributing, ensure you have: Python 3.8 or higher Git installed and configured A GitHub account Basic knowledge of Python, Slack APIs, and AI/ML concepts Familiarity with the project architecture (see Architecture Guide ) First Steps \u00b6 Fork the repository on GitHub Clone your fork locally: git clone https://github.com/YOUR_USERNAME/gutless-ai-assistant.git cd gutless-ai-assistant Add the upstream remote : git remote add upstream https://github.com/ORIGINAL_OWNER/gutless-ai-assistant.git Set up the development environment (see Development Setup ) Development Setup \u00b6 Environment Setup \u00b6 Create a virtual environment : python -m venv venv source venv/bin/activate # On Windows: venv\\Scripts\\activate Install dependencies : pip install -r requirements.txt pip install -r requirements-dev.txt # Development dependencies Set up environment variables : cp .env.example .env # Edit .env with your configuration Install pre-commit hooks : pre-commit install Development Dependencies \u00b6 The project uses additional development tools: # Code formatting and linting pip install black flake8 isort mypy # Testing pip install pytest pytest-cov pytest-mock # Documentation pip install -r docs/requirements.txt # Pre-commit hooks pip install pre-commit Running the Application \u00b6 Start the development server : python src/bot.py Run tests : pytest Check code quality : # Format code black . isort . # Lint code flake8 . mypy . Contributing Guidelines \u00b6 Types of Contributions \u00b6 We welcome various types of contributions: Bug fixes : Fix issues and improve stability Feature development : Add new functionality Documentation : Improve or add documentation Testing : Add or improve test coverage Performance : Optimize code performance Refactoring : Improve code structure and maintainability Contribution Workflow \u00b6 Check existing issues to see if your contribution is already being worked on Create an issue if one doesn't exist for your contribution Discuss your approach in the issue before starting work Create a feature branch from the main branch Make your changes following our coding standards Write tests for your changes Update documentation as needed Submit a pull request Branch Naming Convention \u00b6 Use descriptive branch names: feature/add-user-authentication bugfix/fix-slack-connection-timeout docs/update-installation-guide refactor/improve-embedding-service test/add-core-logic-tests Pull Request Process \u00b6 Before Submitting \u00b6 Ensure your pull request: Follows the coding standards Includes appropriate tests Updates relevant documentation Passes all existing tests Has a clear, descriptive title Includes a detailed description Pull Request Template \u00b6 Use this template for your pull requests: ## Description Brief description of the changes made. ## Type of Change - [ ] Bug fix (non-breaking change which fixes an issue) - [ ] New feature (non-breaking change which adds functionality) - [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected) - [ ] Documentation update - [ ] Performance improvement - [ ] Code refactoring ## Testing - [ ] I have added tests that prove my fix is effective or that my feature works - [ ] New and existing unit tests pass locally with my changes - [ ] I have tested the changes manually ## Documentation - [ ] I have updated the documentation accordingly - [ ] I have added docstrings to new functions/classes - [ ] I have updated the API reference if needed ## Checklist - [ ] My code follows the style guidelines of this project - [ ] I have performed a self-review of my own code - [ ] I have commented my code, particularly in hard-to-understand areas - [ ] My changes generate no new warnings - [ ] I have added tests that prove my fix is effective or that my feature works - [ ] New and existing unit tests pass locally with my changes Review Process \u00b6 Automated checks : CI/CD pipeline runs tests and quality checks Code review : Maintainers review your code for quality and correctness Feedback : Address any feedback or requested changes Approval : Once approved, your PR will be merged Coding Standards \u00b6 Python Style Guide \u00b6 We follow PEP 8 with some modifications: Line length : 88 characters (Black default) Imports : Use isort for import organization Type hints : Use type hints for all public functions Docstrings : Use Google-style docstrings Code Formatting \u00b6 We use automated tools for consistent formatting: # Format code black . # Sort imports isort . # Check formatting black --check . isort --check-only . Linting \u00b6 We use flake8 for linting: # Run linter flake8 . # Configuration in setup.cfg [ flake8 ] max-line-length = 88 extend-ignore = E203, W503 exclude = venv, .git, __pycache__ Type Checking \u00b6 We use mypy for static type checking: # Run type checker mypy . # Configuration in mypy.ini [ mypy ] python_version = 3 .8 warn_return_any = True warn_unused_configs = True disallow_untyped_defs = True Documentation Standards \u00b6 Docstring Format \u00b6 Use Google-style docstrings: def process_query ( query : str , user_id : str ) -> QueryResponse : \"\"\"Process a user query and return a response. Args: query: The user's question or request. user_id: Unique identifier for the user. Returns: QueryResponse object containing the answer and metadata. Raises: ValueError: If query is empty or invalid. APIError: If external API calls fail. Example: >>> response = process_query(\"What foods are eliminated?\", \"user123\") >>> print(response.answer) \"In Week 1, the following foods are eliminated...\" \"\"\" Code Comments \u00b6 Use comments sparingly for complex logic Prefer self-documenting code Explain \"why\" not \"what\" Keep comments up-to-date with code changes Testing \u00b6 Testing Framework \u00b6 We use pytest for testing: # Run all tests pytest # Run with coverage pytest --cov = src # Run specific test file pytest tests/test_core_logic.py # Run with verbose output pytest -v Test Structure \u00b6 Organize tests to mirror the source structure: tests/ \u251c\u2500\u2500 conftest.py # Shared fixtures \u251c\u2500\u2500 test_bot.py # Tests for src/bot.py \u251c\u2500\u2500 test_core_logic.py # Tests for src/core_logic.py \u251c\u2500\u2500 test_embedding_service.py # Tests for src/embedding_service.py \u2514\u2500\u2500 integration/ # Integration tests \u251c\u2500\u2500 test_slack_integration.py \u2514\u2500\u2500 test_api_integration.py Writing Tests \u00b6 Unit Tests \u00b6 import pytest from unittest.mock import Mock , patch from src.core_logic import QueryProcessor class TestQueryProcessor : def test_process_query_success ( self ): \"\"\"Test successful query processing.\"\"\" processor = QueryProcessor () result = processor . process_query ( \"test query\" , \"user123\" ) assert result . answer is not None assert result . confidence > 0.5 assert len ( result . sources ) > 0 @patch ( 'src.core_logic.openai_client' ) def test_process_query_api_error ( self , mock_client ): \"\"\"Test handling of API errors.\"\"\" mock_client . side_effect = Exception ( \"API Error\" ) processor = QueryProcessor () with pytest . raises ( APIError ): processor . process_query ( \"test query\" , \"user123\" ) Integration Tests \u00b6 import pytest from src.bot import SlackBot @pytest . mark . integration class TestSlackIntegration : def test_bot_responds_to_mention ( self , slack_client ): \"\"\"Test bot responds when mentioned.\"\"\" bot = SlackBot () response = bot . handle_mention ( \"@bot what is Week 1?\" ) assert response is not None assert \"Week 1\" in response Test Coverage \u00b6 Maintain high test coverage: Minimum : 80% overall coverage Target : 90%+ for core modules Critical paths : 100% coverage for error handling # Generate coverage report pytest --cov = src --cov-report = html # View coverage report open htmlcov/index.html Mocking External Services \u00b6 Mock external API calls in tests: @patch ( 'src.services.openai_client' ) @patch ( 'src.services.pinecone_client' ) def test_query_processing ( mock_pinecone , mock_openai ): # Mock responses mock_pinecone . query . return_value = mock_search_results mock_openai . chat . completions . create . return_value = mock_completion # Test your code result = process_query ( \"test query\" ) assert result . answer == \"expected answer\" Documentation \u00b6 Documentation Types \u00b6 Code documentation : Docstrings and comments User documentation : Usage guides and tutorials Developer documentation : Architecture and API reference Process documentation : Contributing and deployment guides Writing Documentation \u00b6 Markdown Guidelines \u00b6 Use clear, concise language Include code examples Add table of contents for long documents Use consistent formatting Include links to related documentation Code Examples \u00b6 Include working code examples: # Good: Complete, runnable example from src.core_logic import QueryProcessor processor = QueryProcessor () response = processor . process_query ( query = \"What foods should I avoid in Week 1?\" , user_id = \"user123\" ) print ( f \"Answer: { response . answer } \" ) print ( f \"Sources: { [ s . title for s in response . sources ] } \" ) API Documentation \u00b6 Document all public APIs: class QueryProcessor : \"\"\"Processes user queries and generates responses. This class handles the core logic for processing user questions, including embedding generation, vector search, and response generation. Attributes: embedding_service: Service for generating text embeddings. pinecone_service: Service for vector database operations. llm_service: Service for language model interactions. Example: >>> processor = QueryProcessor() >>> response = processor.process_query(\"What is Week 1?\", \"user123\") >>> print(response.answer) \"\"\" Building Documentation \u00b6 We use a modern documentation framework: # Install documentation dependencies pip install -r docs/requirements.txt # Serve documentation locally python -m http.server 8000 --directory site # Build documentation npm run build Issue Reporting \u00b6 Bug Reports \u00b6 When reporting bugs, include: Clear title : Descriptive summary of the issue Environment : Python version, OS, dependencies Steps to reproduce : Detailed steps to recreate the bug Expected behavior : What should happen Actual behavior : What actually happens Error messages : Full error messages and stack traces Additional context : Screenshots, logs, or other relevant information Bug Report Template \u00b6 **Bug Description** A clear and concise description of what the bug is. **To Reproduce** Steps to reproduce the behavior: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error **Expected Behavior** A clear and concise description of what you expected to happen. **Screenshots** If applicable, add screenshots to help explain your problem. **Environment:** - OS: [e.g. Windows 10, macOS 12.0, Ubuntu 20.04] - Python Version: [e.g. 3.9.7] - Project Version: [e.g. 1.0.0] **Additional Context** Add any other context about the problem here. Feature Requests \u00b6 Proposing Features \u00b6 Before proposing a feature: Check existing issues to avoid duplicates Consider the scope : Does it fit the project goals? Think about implementation : Is it technically feasible? Consider maintenance : Will it require ongoing support? Feature Request Template \u00b6 **Feature Description** A clear and concise description of the feature you'd like to see. **Problem Statement** Describe the problem this feature would solve. **Proposed Solution** Describe the solution you'd like to see implemented. **Alternatives Considered** Describe any alternative solutions or features you've considered. **Use Cases** Provide specific examples of how this feature would be used. **Implementation Notes** Any technical considerations or implementation ideas. **Additional Context** Add any other context, mockups, or examples about the feature request. Community \u00b6 Communication Channels \u00b6 GitHub Issues : Bug reports and feature requests GitHub Discussions : General questions and discussions Slack Workspace : Real-time communication (if available) Email : Direct contact with maintainers Getting Help \u00b6 Check documentation : Start with existing docs Search issues : Look for similar problems Ask questions : Use GitHub Discussions Be specific : Provide context and details Be patient : Maintainers are volunteers Helping Others \u00b6 Answer questions in discussions Review pull requests Improve documentation Share your experience Mentor newcomers Release Process \u00b6 Versioning \u00b6 We follow Semantic Versioning : MAJOR : Incompatible API changes MINOR : New functionality (backward compatible) PATCH : Bug fixes (backward compatible) Release Checklist \u00b6 Update version numbers Update CHANGELOG.md Run full test suite Update documentation Create release notes Tag release in Git Deploy to production Recognition \u00b6 We appreciate all contributions! Contributors will be: Listed in the project's contributors file Mentioned in release notes for significant contributions Invited to join the maintainers team for sustained contributions Questions? \u00b6 If you have questions about contributing: Check this guide first Search existing issues and discussions Create a new discussion with your question Contact maintainers directly if needed Thank you for contributing to the Renesis AI Assistant! \ud83d\ude80","title":"Contributing Guide"},{"location":"contributing/#contributing-to-renesis-ai-assistant","text":"Thank you for your interest in contributing to the Renesis AI Assistant! This guide will help you get started with contributing to the project.","title":"Contributing to Renesis AI Assistant"},{"location":"contributing/#table-of-contents","text":"Code of Conduct Getting Started Development Setup Contributing Guidelines Pull Request Process Coding Standards Testing Documentation Issue Reporting Feature Requests Community","title":"Table of Contents"},{"location":"contributing/#code-of-conduct","text":"By participating in this project, you agree to abide by our Code of Conduct: Be respectful : Treat all contributors with respect and kindness Be inclusive : Welcome newcomers and help them get started Be constructive : Provide helpful feedback and suggestions Be professional : Maintain a professional tone in all communications Be patient : Remember that everyone has different skill levels and backgrounds","title":"Code of Conduct"},{"location":"contributing/#getting-started","text":"","title":"Getting Started"},{"location":"contributing/#prerequisites","text":"Before contributing, ensure you have: Python 3.8 or higher Git installed and configured A GitHub account Basic knowledge of Python, Slack APIs, and AI/ML concepts Familiarity with the project architecture (see Architecture Guide )","title":"Prerequisites"},{"location":"contributing/#first-steps","text":"Fork the repository on GitHub Clone your fork locally: git clone https://github.com/YOUR_USERNAME/gutless-ai-assistant.git cd gutless-ai-assistant Add the upstream remote : git remote add upstream https://github.com/ORIGINAL_OWNER/gutless-ai-assistant.git Set up the development environment (see Development Setup )","title":"First Steps"},{"location":"contributing/#development-setup","text":"","title":"Development Setup"},{"location":"contributing/#environment-setup","text":"Create a virtual environment : python -m venv venv source venv/bin/activate # On Windows: venv\\Scripts\\activate Install dependencies : pip install -r requirements.txt pip install -r requirements-dev.txt # Development dependencies Set up environment variables : cp .env.example .env # Edit .env with your configuration Install pre-commit hooks : pre-commit install","title":"Environment Setup"},{"location":"contributing/#development-dependencies","text":"The project uses additional development tools: # Code formatting and linting pip install black flake8 isort mypy # Testing pip install pytest pytest-cov pytest-mock # Documentation pip install -r docs/requirements.txt # Pre-commit hooks pip install pre-commit","title":"Development Dependencies"},{"location":"contributing/#running-the-application","text":"Start the development server : python src/bot.py Run tests : pytest Check code quality : # Format code black . isort . # Lint code flake8 . mypy .","title":"Running the Application"},{"location":"contributing/#contributing-guidelines","text":"","title":"Contributing Guidelines"},{"location":"contributing/#types-of-contributions","text":"We welcome various types of contributions: Bug fixes : Fix issues and improve stability Feature development : Add new functionality Documentation : Improve or add documentation Testing : Add or improve test coverage Performance : Optimize code performance Refactoring : Improve code structure and maintainability","title":"Types of Contributions"},{"location":"contributing/#contribution-workflow","text":"Check existing issues to see if your contribution is already being worked on Create an issue if one doesn't exist for your contribution Discuss your approach in the issue before starting work Create a feature branch from the main branch Make your changes following our coding standards Write tests for your changes Update documentation as needed Submit a pull request","title":"Contribution Workflow"},{"location":"contributing/#branch-naming-convention","text":"Use descriptive branch names: feature/add-user-authentication bugfix/fix-slack-connection-timeout docs/update-installation-guide refactor/improve-embedding-service test/add-core-logic-tests","title":"Branch Naming Convention"},{"location":"contributing/#pull-request-process","text":"","title":"Pull Request Process"},{"location":"contributing/#before-submitting","text":"Ensure your pull request: Follows the coding standards Includes appropriate tests Updates relevant documentation Passes all existing tests Has a clear, descriptive title Includes a detailed description","title":"Before Submitting"},{"location":"contributing/#pull-request-template","text":"Use this template for your pull requests: ## Description Brief description of the changes made. ## Type of Change - [ ] Bug fix (non-breaking change which fixes an issue) - [ ] New feature (non-breaking change which adds functionality) - [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected) - [ ] Documentation update - [ ] Performance improvement - [ ] Code refactoring ## Testing - [ ] I have added tests that prove my fix is effective or that my feature works - [ ] New and existing unit tests pass locally with my changes - [ ] I have tested the changes manually ## Documentation - [ ] I have updated the documentation accordingly - [ ] I have added docstrings to new functions/classes - [ ] I have updated the API reference if needed ## Checklist - [ ] My code follows the style guidelines of this project - [ ] I have performed a self-review of my own code - [ ] I have commented my code, particularly in hard-to-understand areas - [ ] My changes generate no new warnings - [ ] I have added tests that prove my fix is effective or that my feature works - [ ] New and existing unit tests pass locally with my changes","title":"Pull Request Template"},{"location":"contributing/#review-process","text":"Automated checks : CI/CD pipeline runs tests and quality checks Code review : Maintainers review your code for quality and correctness Feedback : Address any feedback or requested changes Approval : Once approved, your PR will be merged","title":"Review Process"},{"location":"contributing/#coding-standards","text":"","title":"Coding Standards"},{"location":"contributing/#python-style-guide","text":"We follow PEP 8 with some modifications: Line length : 88 characters (Black default) Imports : Use isort for import organization Type hints : Use type hints for all public functions Docstrings : Use Google-style docstrings","title":"Python Style Guide"},{"location":"contributing/#code-formatting","text":"We use automated tools for consistent formatting: # Format code black . # Sort imports isort . # Check formatting black --check . isort --check-only .","title":"Code Formatting"},{"location":"contributing/#linting","text":"We use flake8 for linting: # Run linter flake8 . # Configuration in setup.cfg [ flake8 ] max-line-length = 88 extend-ignore = E203, W503 exclude = venv, .git, __pycache__","title":"Linting"},{"location":"contributing/#type-checking","text":"We use mypy for static type checking: # Run type checker mypy . # Configuration in mypy.ini [ mypy ] python_version = 3 .8 warn_return_any = True warn_unused_configs = True disallow_untyped_defs = True","title":"Type Checking"},{"location":"contributing/#documentation-standards","text":"","title":"Documentation Standards"},{"location":"contributing/#docstring-format","text":"Use Google-style docstrings: def process_query ( query : str , user_id : str ) -> QueryResponse : \"\"\"Process a user query and return a response. Args: query: The user's question or request. user_id: Unique identifier for the user. Returns: QueryResponse object containing the answer and metadata. Raises: ValueError: If query is empty or invalid. APIError: If external API calls fail. Example: >>> response = process_query(\"What foods are eliminated?\", \"user123\") >>> print(response.answer) \"In Week 1, the following foods are eliminated...\" \"\"\"","title":"Docstring Format"},{"location":"contributing/#code-comments","text":"Use comments sparingly for complex logic Prefer self-documenting code Explain \"why\" not \"what\" Keep comments up-to-date with code changes","title":"Code Comments"},{"location":"contributing/#testing","text":"","title":"Testing"},{"location":"contributing/#testing-framework","text":"We use pytest for testing: # Run all tests pytest # Run with coverage pytest --cov = src # Run specific test file pytest tests/test_core_logic.py # Run with verbose output pytest -v","title":"Testing Framework"},{"location":"contributing/#test-structure","text":"Organize tests to mirror the source structure: tests/ \u251c\u2500\u2500 conftest.py # Shared fixtures \u251c\u2500\u2500 test_bot.py # Tests for src/bot.py \u251c\u2500\u2500 test_core_logic.py # Tests for src/core_logic.py \u251c\u2500\u2500 test_embedding_service.py # Tests for src/embedding_service.py \u2514\u2500\u2500 integration/ # Integration tests \u251c\u2500\u2500 test_slack_integration.py \u2514\u2500\u2500 test_api_integration.py","title":"Test Structure"},{"location":"contributing/#writing-tests","text":"","title":"Writing Tests"},{"location":"contributing/#unit-tests","text":"import pytest from unittest.mock import Mock , patch from src.core_logic import QueryProcessor class TestQueryProcessor : def test_process_query_success ( self ): \"\"\"Test successful query processing.\"\"\" processor = QueryProcessor () result = processor . process_query ( \"test query\" , \"user123\" ) assert result . answer is not None assert result . confidence > 0.5 assert len ( result . sources ) > 0 @patch ( 'src.core_logic.openai_client' ) def test_process_query_api_error ( self , mock_client ): \"\"\"Test handling of API errors.\"\"\" mock_client . side_effect = Exception ( \"API Error\" ) processor = QueryProcessor () with pytest . raises ( APIError ): processor . process_query ( \"test query\" , \"user123\" )","title":"Unit Tests"},{"location":"contributing/#integration-tests","text":"import pytest from src.bot import SlackBot @pytest . mark . integration class TestSlackIntegration : def test_bot_responds_to_mention ( self , slack_client ): \"\"\"Test bot responds when mentioned.\"\"\" bot = SlackBot () response = bot . handle_mention ( \"@bot what is Week 1?\" ) assert response is not None assert \"Week 1\" in response","title":"Integration Tests"},{"location":"contributing/#test-coverage","text":"Maintain high test coverage: Minimum : 80% overall coverage Target : 90%+ for core modules Critical paths : 100% coverage for error handling # Generate coverage report pytest --cov = src --cov-report = html # View coverage report open htmlcov/index.html","title":"Test Coverage"},{"location":"contributing/#mocking-external-services","text":"Mock external API calls in tests: @patch ( 'src.services.openai_client' ) @patch ( 'src.services.pinecone_client' ) def test_query_processing ( mock_pinecone , mock_openai ): # Mock responses mock_pinecone . query . return_value = mock_search_results mock_openai . chat . completions . create . return_value = mock_completion # Test your code result = process_query ( \"test query\" ) assert result . answer == \"expected answer\"","title":"Mocking External Services"},{"location":"contributing/#documentation","text":"","title":"Documentation"},{"location":"contributing/#documentation-types","text":"Code documentation : Docstrings and comments User documentation : Usage guides and tutorials Developer documentation : Architecture and API reference Process documentation : Contributing and deployment guides","title":"Documentation Types"},{"location":"contributing/#writing-documentation","text":"","title":"Writing Documentation"},{"location":"contributing/#markdown-guidelines","text":"Use clear, concise language Include code examples Add table of contents for long documents Use consistent formatting Include links to related documentation","title":"Markdown Guidelines"},{"location":"contributing/#code-examples","text":"Include working code examples: # Good: Complete, runnable example from src.core_logic import QueryProcessor processor = QueryProcessor () response = processor . process_query ( query = \"What foods should I avoid in Week 1?\" , user_id = \"user123\" ) print ( f \"Answer: { response . answer } \" ) print ( f \"Sources: { [ s . title for s in response . sources ] } \" )","title":"Code Examples"},{"location":"contributing/#api-documentation","text":"Document all public APIs: class QueryProcessor : \"\"\"Processes user queries and generates responses. This class handles the core logic for processing user questions, including embedding generation, vector search, and response generation. Attributes: embedding_service: Service for generating text embeddings. pinecone_service: Service for vector database operations. llm_service: Service for language model interactions. Example: >>> processor = QueryProcessor() >>> response = processor.process_query(\"What is Week 1?\", \"user123\") >>> print(response.answer) \"\"\"","title":"API Documentation"},{"location":"contributing/#building-documentation","text":"We use a modern documentation framework: # Install documentation dependencies pip install -r docs/requirements.txt # Serve documentation locally python -m http.server 8000 --directory site # Build documentation npm run build","title":"Building Documentation"},{"location":"contributing/#issue-reporting","text":"","title":"Issue Reporting"},{"location":"contributing/#bug-reports","text":"When reporting bugs, include: Clear title : Descriptive summary of the issue Environment : Python version, OS, dependencies Steps to reproduce : Detailed steps to recreate the bug Expected behavior : What should happen Actual behavior : What actually happens Error messages : Full error messages and stack traces Additional context : Screenshots, logs, or other relevant information","title":"Bug Reports"},{"location":"contributing/#bug-report-template","text":"**Bug Description** A clear and concise description of what the bug is. **To Reproduce** Steps to reproduce the behavior: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error **Expected Behavior** A clear and concise description of what you expected to happen. **Screenshots** If applicable, add screenshots to help explain your problem. **Environment:** - OS: [e.g. Windows 10, macOS 12.0, Ubuntu 20.04] - Python Version: [e.g. 3.9.7] - Project Version: [e.g. 1.0.0] **Additional Context** Add any other context about the problem here.","title":"Bug Report Template"},{"location":"contributing/#feature-requests","text":"","title":"Feature Requests"},{"location":"contributing/#proposing-features","text":"Before proposing a feature: Check existing issues to avoid duplicates Consider the scope : Does it fit the project goals? Think about implementation : Is it technically feasible? Consider maintenance : Will it require ongoing support?","title":"Proposing Features"},{"location":"contributing/#feature-request-template","text":"**Feature Description** A clear and concise description of the feature you'd like to see. **Problem Statement** Describe the problem this feature would solve. **Proposed Solution** Describe the solution you'd like to see implemented. **Alternatives Considered** Describe any alternative solutions or features you've considered. **Use Cases** Provide specific examples of how this feature would be used. **Implementation Notes** Any technical considerations or implementation ideas. **Additional Context** Add any other context, mockups, or examples about the feature request.","title":"Feature Request Template"},{"location":"contributing/#community","text":"","title":"Community"},{"location":"contributing/#communication-channels","text":"GitHub Issues : Bug reports and feature requests GitHub Discussions : General questions and discussions Slack Workspace : Real-time communication (if available) Email : Direct contact with maintainers","title":"Communication Channels"},{"location":"contributing/#getting-help","text":"Check documentation : Start with existing docs Search issues : Look for similar problems Ask questions : Use GitHub Discussions Be specific : Provide context and details Be patient : Maintainers are volunteers","title":"Getting Help"},{"location":"contributing/#helping-others","text":"Answer questions in discussions Review pull requests Improve documentation Share your experience Mentor newcomers","title":"Helping Others"},{"location":"contributing/#release-process","text":"","title":"Release Process"},{"location":"contributing/#versioning","text":"We follow Semantic Versioning : MAJOR : Incompatible API changes MINOR : New functionality (backward compatible) PATCH : Bug fixes (backward compatible)","title":"Versioning"},{"location":"contributing/#release-checklist","text":"Update version numbers Update CHANGELOG.md Run full test suite Update documentation Create release notes Tag release in Git Deploy to production","title":"Release Checklist"},{"location":"contributing/#recognition","text":"We appreciate all contributions! Contributors will be: Listed in the project's contributors file Mentioned in release notes for significant contributions Invited to join the maintainers team for sustained contributions","title":"Recognition"},{"location":"contributing/#questions","text":"If you have questions about contributing: Check this guide first Search existing issues and discussions Create a new discussion with your question Contact maintainers directly if needed Thank you for contributing to the Renesis AI Assistant! \ud83d\ude80","title":"Questions?"},{"location":"deployment/","text":"Deployment Guide \u00b6 This guide covers various deployment options for the Renesis AI Assistant Slack bot. Overview \u00b6 The Renesis AI Assistant can be deployed in several ways: Local Development : Using Docker Compose for local testing Cloud Platforms : Deploy to AWS, Google Cloud, Azure, or Heroku Container Orchestration : Using Kubernetes or Docker Swarm Serverless : Using AWS Lambda, Google Cloud Functions, or Azure Functions Prerequisites \u00b6 Required Software \u00b6 Docker and Docker Compose Git A Slack workspace with bot creation permissions Required API Keys \u00b6 Slack Bot Token ( SLACK_BOT_TOKEN ) Slack Signing Secret ( SLACK_SIGNING_SECRET ) Slack App Token ( SLACK_APP_TOKEN ) for Socket Mode OpenAI API Key ( OPENAI_API_KEY ) Pinecone API Key ( PINECONE_API_KEY ) Quick Start (Docker Compose) \u00b6 1. Clone and Setup \u00b6 # Clone the repository git clone <repository-url> cd gutless-ai-assistant # Copy environment template cp .env.example .env 2. Configure Environment \u00b6 Edit the .env file with your actual API keys: # Slack Configuration SLACK_BOT_TOKEN = xoxb-your-bot-token-here SLACK_SIGNING_SECRET = your-signing-secret-here SLACK_APP_TOKEN = xapp-your-app-token-here # OpenAI Configuration OPENAI_API_KEY = sk-your-openai-api-key-here # Pinecone Configuration PINECONE_API_KEY = your-pinecone-api-key-here PINECONE_ENVIRONMENT = us-west1-gcp PINECONE_INDEX_NAME = gutless-ai-assistant 3. Deploy Using Scripts \u00b6 Linux/macOS \u00b6 # Make script executable chmod +x deploy.sh # Setup and start ./deploy.sh setup ./deploy.sh start # View logs ./deploy.sh logs Windows (PowerShell) \u00b6 # Setup and start .\\ deploy . ps1 setup .\\ deploy . ps1 start # View logs .\\ deploy . ps1 logs 4. Manual Docker Compose \u00b6 # Build and start docker-compose up -d # View logs docker-compose logs -f gutless-ai-assistant # Stop docker-compose down Cloud Platform Deployment \u00b6 AWS Deployment \u00b6 Option 1: AWS ECS (Recommended) \u00b6 Create ECS Cluster : aws ecs create-cluster --cluster-name gutless-ai-assistant Create Task Definition : { \"family\" : \"gutless-ai-assistant\" , \"networkMode\" : \"awsvpc\" , \"requiresCompatibilities\" : [ \"FARGATE\" ], \"cpu\" : \"256\" , \"memory\" : \"512\" , \"executionRoleArn\" : \"arn:aws:iam::ACCOUNT:role/ecsTaskExecutionRole\" , \"containerDefinitions\" : [ { \"name\" : \"gutless-ai-assistant\" , \"image\" : \"ghcr.io/your-username/gutless-ai-assistant:latest\" , \"essential\" : true , \"environment\" : [ { \"name\" : \"SLACK_BOT_TOKEN\" , \"value\" : \"${SLACK_BOT_TOKEN}\" }, { \"name\" : \"SLACK_SIGNING_SECRET\" , \"value\" : \"${SLACK_SIGNING_SECRET}\" }, { \"name\" : \"SLACK_APP_TOKEN\" , \"value\" : \"${SLACK_APP_TOKEN}\" }, { \"name\" : \"OPENAI_API_KEY\" , \"value\" : \"${OPENAI_API_KEY}\" }, { \"name\" : \"PINECONE_API_KEY\" , \"value\" : \"${PINECONE_API_KEY}\" } ], \"logConfiguration\" : { \"logDriver\" : \"awslogs\" , \"options\" : { \"awslogs-group\" : \"/ecs/gutless-ai-assistant\" , \"awslogs-region\" : \"us-west-2\" , \"awslogs-stream-prefix\" : \"ecs\" } } } ] } Create Service : aws ecs create-service \\ --cluster gutless-ai-assistant \\ --service-name gutless-ai-assistant \\ --task-definition gutless-ai-assistant \\ --desired-count 1 \\ --launch-type FARGATE \\ --network-configuration \"awsvpcConfiguration={subnets=[subnet-12345],securityGroups=[sg-12345],assignPublicIp=ENABLED}\" Option 2: AWS Lambda (Serverless) \u00b6 Install Serverless Framework : npm install -g serverless Create serverless.yml : service : gutless-ai-assistant provider : name : aws runtime : python3.11 region : us-west-2 environment : SLACK_BOT_TOKEN : ${env:SLACK_BOT_TOKEN} SLACK_SIGNING_SECRET : ${env:SLACK_SIGNING_SECRET} OPENAI_API_KEY : ${env:OPENAI_API_KEY} PINECONE_API_KEY : ${env:PINECONE_API_KEY} functions : slack-bot : handler : src.lambda_handler.handler events : - http : path : slack/events method : post Google Cloud Deployment \u00b6 Google Cloud Run \u00b6 Build and push image : # Configure Docker for GCR gcloud auth configure-docker # Build and push docker build -t gcr.io/PROJECT-ID/gutless-ai-assistant . docker push gcr.io/PROJECT-ID/gutless-ai-assistant Deploy to Cloud Run : gcloud run deploy gutless-ai-assistant \\ --image gcr.io/PROJECT-ID/gutless-ai-assistant \\ --platform managed \\ --region us-central1 \\ --set-env-vars SLACK_BOT_TOKEN = $SLACK_BOT_TOKEN ,SLACK_SIGNING_SECRET = $SLACK_SIGNING_SECRET ,SLACK_APP_TOKEN = $SLACK_APP_TOKEN ,OPENAI_API_KEY = $OPENAI_API_KEY ,PINECONE_API_KEY = $PINECONE_API_KEY Azure Deployment \u00b6 Azure Container Instances \u00b6 Create resource group : az group create --name gutless-ai-assistant --location eastus Deploy container : az container create \\ --resource-group gutless-ai-assistant \\ --name gutless-ai-assistant \\ --image ghcr.io/your-username/gutless-ai-assistant:latest \\ --environment-variables \\ SLACK_BOT_TOKEN = $SLACK_BOT_TOKEN \\ SLACK_SIGNING_SECRET = $SLACK_SIGNING_SECRET \\ SLACK_APP_TOKEN = $SLACK_APP_TOKEN \\ OPENAI_API_KEY = $OPENAI_API_KEY \\ PINECONE_API_KEY = $PINECONE_API_KEY Heroku Deployment \u00b6 Install Heroku CLI and login: heroku login Create Heroku app : heroku create gutless-ai-assistant Set environment variables : heroku config:set SLACK_BOT_TOKEN = your-token heroku config:set SLACK_SIGNING_SECRET = your-secret heroku config:set SLACK_APP_TOKEN = your-app-token heroku config:set OPENAI_API_KEY = your-openai-key heroku config:set PINECONE_API_KEY = your-pinecone-key heroku config:set PINECONE_ENVIRONMENT = us-west1-gcp heroku config:set PINECONE_INDEX_NAME = gutless-ai-assistant Deploy : # Using Docker heroku container:push web heroku container:release web # Or using Git git push heroku main Kubernetes Deployment \u00b6 1. Create Namespace \u00b6 # namespace.yaml apiVersion : v1 kind : Namespace metadata : name : gutless-ai-assistant 2. Create Secret \u00b6 # secret.yaml apiVersion : v1 kind : Secret metadata : name : gutless-ai-assistant-secrets namespace : gutless-ai-assistant type : Opaque stringData : SLACK_BOT_TOKEN : \"xoxb-your-bot-token\" SLACK_SIGNING_SECRET : \"your-signing-secret\" SLACK_APP_TOKEN : \"xapp-your-app-token\" OPENAI_API_KEY : \"sk-your-openai-key\" PINECONE_API_KEY : \"your-pinecone-key\" PINECONE_ENVIRONMENT : \"us-west1-gcp\" PINECONE_INDEX_NAME : \"gutless-ai-assistant\" 3. Create Deployment \u00b6 # deployment.yaml apiVersion : apps/v1 kind : Deployment metadata : name : gutless-ai-assistant namespace : gutless-ai-assistant spec : replicas : 1 selector : matchLabels : app : gutless-ai-assistant template : metadata : labels : app : gutless-ai-assistant spec : containers : - name : gutless-ai-assistant image : ghcr.io/your-username/gutless-ai-assistant:latest envFrom : - secretRef : name : gutless-ai-assistant-secrets resources : requests : memory : \"256Mi\" cpu : \"250m\" limits : memory : \"512Mi\" cpu : \"500m\" livenessProbe : exec : command : - python - -c - \"import sys; sys.exit(0)\" initialDelaySeconds : 30 periodSeconds : 30 readinessProbe : exec : command : - python - -c - \"import sys; sys.exit(0)\" initialDelaySeconds : 5 periodSeconds : 10 4. Deploy to Kubernetes \u00b6 kubectl apply -f namespace.yaml kubectl apply -f secret.yaml kubectl apply -f deployment.yaml CI/CD with GitHub Actions \u00b6 The repository includes a GitHub Actions workflow ( .github/workflows/deploy.yml ) that: Tests the application Builds and pushes Docker images Scans for security vulnerabilities Deploys to staging and production environments Setup GitHub Actions \u00b6 Configure secrets in your GitHub repository: SLACK_BOT_TOKEN SLACK_SIGNING_SECRET SLACK_APP_TOKEN OPENAI_API_KEY PINECONE_API_KEY Cloud platform credentials (AWS, GCP, Azure) Customize deployment targets in .github/workflows/deploy.yml Push to main branch or create a tag to trigger deployment Monitoring and Logging \u00b6 Application Logs \u00b6 # Docker Compose docker-compose logs -f gutless-ai-assistant # Kubernetes kubectl logs -f deployment/gutless-ai-assistant -n gutless-ai-assistant # AWS ECS aws logs tail /ecs/gutless-ai-assistant --follow Health Checks \u00b6 The application includes health check endpoints that can be used with: Docker : Built-in health checks Kubernetes : Liveness and readiness probes Cloud platforms : Load balancer health checks Monitoring Tools \u00b6 Prometheus + Grafana : For metrics collection and visualization ELK Stack : For centralized logging Cloud monitoring : AWS CloudWatch, Google Cloud Monitoring, Azure Monitor Troubleshooting \u00b6 Common Issues \u00b6 Environment Variables : Ensure all required environment variables are set API Keys : Verify API keys are valid and have proper permissions Network : Check firewall rules and security groups Resources : Monitor CPU and memory usage Dependencies : Ensure external services (Pinecone, OpenAI) are accessible Debug Mode \u00b6 Enable debug logging by setting: LOG_LEVEL = DEBUG DEVELOPMENT_MODE = true Support \u00b6 For deployment issues: Check the troubleshooting guide Review application logs Verify configuration settings Test API connectivity Security Considerations \u00b6 Secrets Management : Use proper secret management services Network Security : Implement proper firewall rules Image Security : Regularly scan Docker images for vulnerabilities Access Control : Use least privilege principles Monitoring : Implement security monitoring and alerting Scaling \u00b6 Horizontal Scaling \u00b6 Kubernetes : Use Horizontal Pod Autoscaler (HPA) Cloud platforms : Configure auto-scaling groups Load balancing : Distribute traffic across multiple instances Vertical Scaling \u00b6 Resource limits : Adjust CPU and memory limits Instance types : Use appropriate instance sizes Performance monitoring : Monitor resource utilization Cost Optimization \u00b6 Right-sizing : Use appropriate instance sizes Auto-scaling : Scale down during low usage Reserved instances : Use reserved instances for predictable workloads Spot instances : Use spot instances for non-critical workloads Resource monitoring : Monitor and optimize resource usage","title":"Deployment"},{"location":"deployment/#deployment-guide","text":"This guide covers various deployment options for the Renesis AI Assistant Slack bot.","title":"Deployment Guide"},{"location":"deployment/#overview","text":"The Renesis AI Assistant can be deployed in several ways: Local Development : Using Docker Compose for local testing Cloud Platforms : Deploy to AWS, Google Cloud, Azure, or Heroku Container Orchestration : Using Kubernetes or Docker Swarm Serverless : Using AWS Lambda, Google Cloud Functions, or Azure Functions","title":"Overview"},{"location":"deployment/#prerequisites","text":"","title":"Prerequisites"},{"location":"deployment/#required-software","text":"Docker and Docker Compose Git A Slack workspace with bot creation permissions","title":"Required Software"},{"location":"deployment/#required-api-keys","text":"Slack Bot Token ( SLACK_BOT_TOKEN ) Slack Signing Secret ( SLACK_SIGNING_SECRET ) Slack App Token ( SLACK_APP_TOKEN ) for Socket Mode OpenAI API Key ( OPENAI_API_KEY ) Pinecone API Key ( PINECONE_API_KEY )","title":"Required API Keys"},{"location":"deployment/#quick-start-docker-compose","text":"","title":"Quick Start (Docker Compose)"},{"location":"deployment/#1-clone-and-setup","text":"# Clone the repository git clone <repository-url> cd gutless-ai-assistant # Copy environment template cp .env.example .env","title":"1. Clone and Setup"},{"location":"deployment/#2-configure-environment","text":"Edit the .env file with your actual API keys: # Slack Configuration SLACK_BOT_TOKEN = xoxb-your-bot-token-here SLACK_SIGNING_SECRET = your-signing-secret-here SLACK_APP_TOKEN = xapp-your-app-token-here # OpenAI Configuration OPENAI_API_KEY = sk-your-openai-api-key-here # Pinecone Configuration PINECONE_API_KEY = your-pinecone-api-key-here PINECONE_ENVIRONMENT = us-west1-gcp PINECONE_INDEX_NAME = gutless-ai-assistant","title":"2. Configure Environment"},{"location":"deployment/#3-deploy-using-scripts","text":"","title":"3. Deploy Using Scripts"},{"location":"deployment/#linuxmacos","text":"# Make script executable chmod +x deploy.sh # Setup and start ./deploy.sh setup ./deploy.sh start # View logs ./deploy.sh logs","title":"Linux/macOS"},{"location":"deployment/#windows-powershell","text":"# Setup and start .\\ deploy . ps1 setup .\\ deploy . ps1 start # View logs .\\ deploy . ps1 logs","title":"Windows (PowerShell)"},{"location":"deployment/#4-manual-docker-compose","text":"# Build and start docker-compose up -d # View logs docker-compose logs -f gutless-ai-assistant # Stop docker-compose down","title":"4. Manual Docker Compose"},{"location":"deployment/#cloud-platform-deployment","text":"","title":"Cloud Platform Deployment"},{"location":"deployment/#aws-deployment","text":"","title":"AWS Deployment"},{"location":"deployment/#option-1-aws-ecs-recommended","text":"Create ECS Cluster : aws ecs create-cluster --cluster-name gutless-ai-assistant Create Task Definition : { \"family\" : \"gutless-ai-assistant\" , \"networkMode\" : \"awsvpc\" , \"requiresCompatibilities\" : [ \"FARGATE\" ], \"cpu\" : \"256\" , \"memory\" : \"512\" , \"executionRoleArn\" : \"arn:aws:iam::ACCOUNT:role/ecsTaskExecutionRole\" , \"containerDefinitions\" : [ { \"name\" : \"gutless-ai-assistant\" , \"image\" : \"ghcr.io/your-username/gutless-ai-assistant:latest\" , \"essential\" : true , \"environment\" : [ { \"name\" : \"SLACK_BOT_TOKEN\" , \"value\" : \"${SLACK_BOT_TOKEN}\" }, { \"name\" : \"SLACK_SIGNING_SECRET\" , \"value\" : \"${SLACK_SIGNING_SECRET}\" }, { \"name\" : \"SLACK_APP_TOKEN\" , \"value\" : \"${SLACK_APP_TOKEN}\" }, { \"name\" : \"OPENAI_API_KEY\" , \"value\" : \"${OPENAI_API_KEY}\" }, { \"name\" : \"PINECONE_API_KEY\" , \"value\" : \"${PINECONE_API_KEY}\" } ], \"logConfiguration\" : { \"logDriver\" : \"awslogs\" , \"options\" : { \"awslogs-group\" : \"/ecs/gutless-ai-assistant\" , \"awslogs-region\" : \"us-west-2\" , \"awslogs-stream-prefix\" : \"ecs\" } } } ] } Create Service : aws ecs create-service \\ --cluster gutless-ai-assistant \\ --service-name gutless-ai-assistant \\ --task-definition gutless-ai-assistant \\ --desired-count 1 \\ --launch-type FARGATE \\ --network-configuration \"awsvpcConfiguration={subnets=[subnet-12345],securityGroups=[sg-12345],assignPublicIp=ENABLED}\"","title":"Option 1: AWS ECS (Recommended)"},{"location":"deployment/#option-2-aws-lambda-serverless","text":"Install Serverless Framework : npm install -g serverless Create serverless.yml : service : gutless-ai-assistant provider : name : aws runtime : python3.11 region : us-west-2 environment : SLACK_BOT_TOKEN : ${env:SLACK_BOT_TOKEN} SLACK_SIGNING_SECRET : ${env:SLACK_SIGNING_SECRET} OPENAI_API_KEY : ${env:OPENAI_API_KEY} PINECONE_API_KEY : ${env:PINECONE_API_KEY} functions : slack-bot : handler : src.lambda_handler.handler events : - http : path : slack/events method : post","title":"Option 2: AWS Lambda (Serverless)"},{"location":"deployment/#google-cloud-deployment","text":"","title":"Google Cloud Deployment"},{"location":"deployment/#google-cloud-run","text":"Build and push image : # Configure Docker for GCR gcloud auth configure-docker # Build and push docker build -t gcr.io/PROJECT-ID/gutless-ai-assistant . docker push gcr.io/PROJECT-ID/gutless-ai-assistant Deploy to Cloud Run : gcloud run deploy gutless-ai-assistant \\ --image gcr.io/PROJECT-ID/gutless-ai-assistant \\ --platform managed \\ --region us-central1 \\ --set-env-vars SLACK_BOT_TOKEN = $SLACK_BOT_TOKEN ,SLACK_SIGNING_SECRET = $SLACK_SIGNING_SECRET ,SLACK_APP_TOKEN = $SLACK_APP_TOKEN ,OPENAI_API_KEY = $OPENAI_API_KEY ,PINECONE_API_KEY = $PINECONE_API_KEY","title":"Google Cloud Run"},{"location":"deployment/#azure-deployment","text":"","title":"Azure Deployment"},{"location":"deployment/#azure-container-instances","text":"Create resource group : az group create --name gutless-ai-assistant --location eastus Deploy container : az container create \\ --resource-group gutless-ai-assistant \\ --name gutless-ai-assistant \\ --image ghcr.io/your-username/gutless-ai-assistant:latest \\ --environment-variables \\ SLACK_BOT_TOKEN = $SLACK_BOT_TOKEN \\ SLACK_SIGNING_SECRET = $SLACK_SIGNING_SECRET \\ SLACK_APP_TOKEN = $SLACK_APP_TOKEN \\ OPENAI_API_KEY = $OPENAI_API_KEY \\ PINECONE_API_KEY = $PINECONE_API_KEY","title":"Azure Container Instances"},{"location":"deployment/#heroku-deployment","text":"Install Heroku CLI and login: heroku login Create Heroku app : heroku create gutless-ai-assistant Set environment variables : heroku config:set SLACK_BOT_TOKEN = your-token heroku config:set SLACK_SIGNING_SECRET = your-secret heroku config:set SLACK_APP_TOKEN = your-app-token heroku config:set OPENAI_API_KEY = your-openai-key heroku config:set PINECONE_API_KEY = your-pinecone-key heroku config:set PINECONE_ENVIRONMENT = us-west1-gcp heroku config:set PINECONE_INDEX_NAME = gutless-ai-assistant Deploy : # Using Docker heroku container:push web heroku container:release web # Or using Git git push heroku main","title":"Heroku Deployment"},{"location":"deployment/#kubernetes-deployment","text":"","title":"Kubernetes Deployment"},{"location":"deployment/#1-create-namespace","text":"# namespace.yaml apiVersion : v1 kind : Namespace metadata : name : gutless-ai-assistant","title":"1. Create Namespace"},{"location":"deployment/#2-create-secret","text":"# secret.yaml apiVersion : v1 kind : Secret metadata : name : gutless-ai-assistant-secrets namespace : gutless-ai-assistant type : Opaque stringData : SLACK_BOT_TOKEN : \"xoxb-your-bot-token\" SLACK_SIGNING_SECRET : \"your-signing-secret\" SLACK_APP_TOKEN : \"xapp-your-app-token\" OPENAI_API_KEY : \"sk-your-openai-key\" PINECONE_API_KEY : \"your-pinecone-key\" PINECONE_ENVIRONMENT : \"us-west1-gcp\" PINECONE_INDEX_NAME : \"gutless-ai-assistant\"","title":"2. Create Secret"},{"location":"deployment/#3-create-deployment","text":"# deployment.yaml apiVersion : apps/v1 kind : Deployment metadata : name : gutless-ai-assistant namespace : gutless-ai-assistant spec : replicas : 1 selector : matchLabels : app : gutless-ai-assistant template : metadata : labels : app : gutless-ai-assistant spec : containers : - name : gutless-ai-assistant image : ghcr.io/your-username/gutless-ai-assistant:latest envFrom : - secretRef : name : gutless-ai-assistant-secrets resources : requests : memory : \"256Mi\" cpu : \"250m\" limits : memory : \"512Mi\" cpu : \"500m\" livenessProbe : exec : command : - python - -c - \"import sys; sys.exit(0)\" initialDelaySeconds : 30 periodSeconds : 30 readinessProbe : exec : command : - python - -c - \"import sys; sys.exit(0)\" initialDelaySeconds : 5 periodSeconds : 10","title":"3. Create Deployment"},{"location":"deployment/#4-deploy-to-kubernetes","text":"kubectl apply -f namespace.yaml kubectl apply -f secret.yaml kubectl apply -f deployment.yaml","title":"4. Deploy to Kubernetes"},{"location":"deployment/#cicd-with-github-actions","text":"The repository includes a GitHub Actions workflow ( .github/workflows/deploy.yml ) that: Tests the application Builds and pushes Docker images Scans for security vulnerabilities Deploys to staging and production environments","title":"CI/CD with GitHub Actions"},{"location":"deployment/#setup-github-actions","text":"Configure secrets in your GitHub repository: SLACK_BOT_TOKEN SLACK_SIGNING_SECRET SLACK_APP_TOKEN OPENAI_API_KEY PINECONE_API_KEY Cloud platform credentials (AWS, GCP, Azure) Customize deployment targets in .github/workflows/deploy.yml Push to main branch or create a tag to trigger deployment","title":"Setup GitHub Actions"},{"location":"deployment/#monitoring-and-logging","text":"","title":"Monitoring and Logging"},{"location":"deployment/#application-logs","text":"# Docker Compose docker-compose logs -f gutless-ai-assistant # Kubernetes kubectl logs -f deployment/gutless-ai-assistant -n gutless-ai-assistant # AWS ECS aws logs tail /ecs/gutless-ai-assistant --follow","title":"Application Logs"},{"location":"deployment/#health-checks","text":"The application includes health check endpoints that can be used with: Docker : Built-in health checks Kubernetes : Liveness and readiness probes Cloud platforms : Load balancer health checks","title":"Health Checks"},{"location":"deployment/#monitoring-tools","text":"Prometheus + Grafana : For metrics collection and visualization ELK Stack : For centralized logging Cloud monitoring : AWS CloudWatch, Google Cloud Monitoring, Azure Monitor","title":"Monitoring Tools"},{"location":"deployment/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"deployment/#common-issues","text":"Environment Variables : Ensure all required environment variables are set API Keys : Verify API keys are valid and have proper permissions Network : Check firewall rules and security groups Resources : Monitor CPU and memory usage Dependencies : Ensure external services (Pinecone, OpenAI) are accessible","title":"Common Issues"},{"location":"deployment/#debug-mode","text":"Enable debug logging by setting: LOG_LEVEL = DEBUG DEVELOPMENT_MODE = true","title":"Debug Mode"},{"location":"deployment/#support","text":"For deployment issues: Check the troubleshooting guide Review application logs Verify configuration settings Test API connectivity","title":"Support"},{"location":"deployment/#security-considerations","text":"Secrets Management : Use proper secret management services Network Security : Implement proper firewall rules Image Security : Regularly scan Docker images for vulnerabilities Access Control : Use least privilege principles Monitoring : Implement security monitoring and alerting","title":"Security Considerations"},{"location":"deployment/#scaling","text":"","title":"Scaling"},{"location":"deployment/#horizontal-scaling","text":"Kubernetes : Use Horizontal Pod Autoscaler (HPA) Cloud platforms : Configure auto-scaling groups Load balancing : Distribute traffic across multiple instances","title":"Horizontal Scaling"},{"location":"deployment/#vertical-scaling","text":"Resource limits : Adjust CPU and memory limits Instance types : Use appropriate instance sizes Performance monitoring : Monitor resource utilization","title":"Vertical Scaling"},{"location":"deployment/#cost-optimization","text":"Right-sizing : Use appropriate instance sizes Auto-scaling : Scale down during low usage Reserved instances : Use reserved instances for predictable workloads Spot instances : Use spot instances for non-critical workloads Resource monitoring : Monitor and optimize resource usage","title":"Cost Optimization"},{"location":"faq/","text":"Frequently Asked Questions (FAQ) \u00b6 This document answers common questions about the Renesis AI Assistant. General Questions \u00b6 What is the Renesis AI Assistant? \u00b6 The Renesis AI Assistant is an AI-powered Slack bot designed to provide intelligent responses and assistance. It uses advanced natural language processing (GPT-4o) and vector search technology (Pinecone) to provide accurate, contextual answers with source references. What content does the bot have access to? \u00b6 Currently, the bot has access to: - Week 1 coaching call transcripts - Week 1 PDF materials and guides - Program protocols and procedures for Week 1 - Troubleshooting guides and FAQs for Week 1 Note : The bot is limited to Week 1 content only in this MVP version. How accurate are the bot's responses? \u00b6 The bot aims for 80-90% accuracy on common Week 1 questions. Accuracy depends on: - Quality of the source content - Clarity of the user's question - Availability of relevant information in the knowledge base Can the bot provide medical advice? \u00b6 No. The bot provides educational information based on program content but cannot: - Diagnose medical conditions - Provide personalized medical advice - Replace consultation with healthcare professionals - Make treatment recommendations Always consult with qualified healthcare providers for medical concerns. Usage Questions \u00b6 How do I ask the bot a question? \u00b6 There are several ways to interact with the bot: In channels : Mention the bot with your question @gutless-assistant What foods should I avoid in Week 1? Direct messages : Send a direct message to the bot Can you explain the elimination protocol? Thread replies : The bot can continue conversations in threads What types of questions can I ask? \u00b6 You can ask about: - Protocols : \"What's the Week 1 morning routine?\" - Foods : \"What can I eat during the elimination phase?\" - Symptoms : \"What symptoms are normal in Week 1?\" - Procedures : \"How do I prepare for Week 1?\" - Troubleshooting : \"I'm having issues with [specific problem]\" - Clarifications : \"Can you explain [specific concept] better?\" Why doesn't the bot understand my question? \u00b6 Common reasons include: - Too vague : \"Help me\" vs. \"What foods should I avoid in Week 1?\" - Outside scope : Questions about Week 2+ content - Unclear phrasing : Try rephrasing more specifically - Missing context : Include relevant details How long does it take to get a response? \u00b6 Typical response time : 2-5 seconds Complex questions : 5-10 seconds High load periods : Up to 30 seconds If no response after 30 seconds, try asking again. Can I ask follow-up questions? \u00b6 Yes! The bot can handle follow-up questions in the same conversation thread. For example: User: What foods are eliminated in Week 1? Bot: [Lists eliminated foods] User: Why are these foods eliminated? Bot: [Explains the reasoning] Technical Questions \u00b6 What technology powers the bot? \u00b6 The bot uses: - AI Model : OpenAI GPT-4o for answer generation - Embeddings : OpenAI text-embedding-ada-002 for semantic search - Vector Database : Pinecone for content storage and retrieval - Platform : Slack Bolt SDK for Python - Transcription : OpenAI Whisper for audio processing How does the bot find relevant information? \u00b6 The process involves: 1. Query embedding : Your question is converted to a vector 2. Similarity search : The vector database finds similar content 3. Context assembly : Relevant chunks are combined 4. Answer generation : GPT-4o creates an answer using the context 5. Source linking : References are added to the response Is my data private and secure? \u00b6 Privacy measures : - Questions and responses are logged for improvement purposes only - No personal health data is stored beyond what you share in questions - All API communications use HTTPS encryption - Data is handled according to privacy best practices What's stored : - Your questions and bot responses (for analytics) - Slack user IDs (for logging purposes) What's NOT stored : - Private Slack conversations outside bot interactions - Personal files or attachments - Sensitive personal information Can I use the bot offline? \u00b6 No, the bot requires internet connectivity to: - Access OpenAI APIs - Query the Pinecone vector database - Communicate with Slack Content and Accuracy Questions \u00b6 What if the bot gives incorrect information? \u00b6 If you notice incorrect information: 1. Cross-reference with original program materials 2. Report the issue with specific details 3. Ask for clarification or rephrase your question 4. Consult program coaches for verification How often is the content updated? \u00b6 Currently, the bot contains Week 1 content that was ingested during setup. Content updates require: - Manual re-ingestion of new materials - System administrator intervention - Potential downtime during updates Can the bot access new Week 1 materials? \u00b6 Not automatically. New materials must be: - Processed through the content ingestion pipeline - Converted to embeddings - Added to the vector database This requires technical intervention. Why does the bot sometimes say \"I don't know\"? \u00b6 This happens when: - The question is outside the Week 1 scope - No relevant content is found in the database - The confidence score is too low - The question is too ambiguous Troubleshooting Questions \u00b6 The bot isn't responding. What should I do? \u00b6 Check bot status : Is it showing as online in Slack? Try rephrasing : Make your question more specific Wait and retry : There might be temporary issues Check spelling : Ensure you're mentioning the correct bot name Try direct message : Sometimes channel mentions fail The bot gave an error message. What does it mean? \u00b6 Error Message Meaning Solution \"I'm having trouble processing your request\" General system error Try again in a few minutes \"No relevant content found\" No matching information Rephrase or ask about Week 1 topics \"Service temporarily unavailable\" API issues Wait and retry \"I can only answer questions about Week 1\" Out of scope Ask about Week 1 content only The response seems incomplete or cut off. Why? \u00b6 This can happen due to: - Token limits : Very long responses may be truncated - Network issues : Connection problems during response - Rate limiting : API limits reached Solution : Ask for specific parts of the information you need. Can I get more detailed information? \u00b6 Yes! Try: - Ask for elaboration : \"Can you explain that in more detail?\" - Request specific aspects : \"What are the specific steps for [process]?\" - Ask for examples : \"Can you give me examples of [concept]?\" - Request sources : \"Where in the video is this discussed?\" Administrative Questions \u00b6 Who can use the bot? \u00b6 Access is typically limited to: - Members of the designated Slack workspace - Gutless program participants - Authorized coaches and staff Can I add the bot to other channels? \u00b6 This depends on: - Bot permissions in your workspace - Channel privacy settings - Administrator policies Try /invite @gutless-assistant in the desired channel. How do I report bugs or suggest improvements? \u00b6 To report issues: 1. Document the problem : What happened vs. what you expected 2. Include context : Your exact question and the bot's response 3. Note timing : When did the issue occur 4. Contact administrators : Through designated support channels Can the bot be customized for our specific needs? \u00b6 Potential customizations include: - Content scope : Adding more weeks or programs - Response style : Adjusting tone or format - Integration : Connecting to other systems - Features : Adding new capabilities Customizations require development work and should be discussed with the technical team. Performance Questions \u00b6 Why are responses sometimes slow? \u00b6 Response time can be affected by: - Question complexity : More complex queries take longer - API load : High usage of OpenAI or Pinecone services - Network conditions : Internet connectivity issues - System load : Multiple concurrent users Can I make the bot respond faster? \u00b6 Tips for faster responses : - Ask specific, focused questions - Avoid very long or complex queries - Use clear, simple language - Ask one question at a time Does the bot work better at certain times? \u00b6 Performance is generally consistent, but may be slower during: - Peak usage hours - API maintenance windows - High network traffic periods Future Development Questions \u00b6 Will the bot support more content in the future? \u00b6 Potential future enhancements: - Week 2+ content : Expanding beyond Week 1 - Multiple programs : Supporting other coaching programs - Interactive features : More sophisticated interactions - Integrations : Connecting to other tools and platforms Can the bot learn from interactions? \u00b6 Currently, the bot: - Logs interactions for analysis - Does not learn automatically from conversations - Requires manual updates to improve responses Future versions might include: - Automatic learning capabilities - Feedback-based improvements - Adaptive response generation How can I stay updated on new features? \u00b6 Stay informed through: - Slack announcements in your workspace - Program communication channels - Documentation updates - Release notes and changelogs Getting More Help \u00b6 Where can I find more detailed documentation? \u00b6 Installation Guide Usage Guide Troubleshooting Guide API Reference Architecture Overview Who should I contact for support? \u00b6 For usage questions : Ask in your Slack workspace or consult this FAQ For technical issues : Contact your system administrator or technical support team For content questions : Consult with program coaches or refer to original materials For feature requests : Submit through designated feedback channels Is there a user community or forum? \u00b6 Check with your program administrators about: - Dedicated Slack channels for bot discussions - User feedback groups - Community forums or resources - Regular Q&A sessions This FAQ is regularly updated. If you have questions not covered here, please reach out through appropriate support channels.","title":"FAQ"},{"location":"faq/#frequently-asked-questions-faq","text":"This document answers common questions about the Renesis AI Assistant.","title":"Frequently Asked Questions (FAQ)"},{"location":"faq/#general-questions","text":"","title":"General Questions"},{"location":"faq/#what-is-the-renesis-ai-assistant","text":"The Renesis AI Assistant is an AI-powered Slack bot designed to provide intelligent responses and assistance. It uses advanced natural language processing (GPT-4o) and vector search technology (Pinecone) to provide accurate, contextual answers with source references.","title":"What is the Renesis AI Assistant?"},{"location":"faq/#what-content-does-the-bot-have-access-to","text":"Currently, the bot has access to: - Week 1 coaching call transcripts - Week 1 PDF materials and guides - Program protocols and procedures for Week 1 - Troubleshooting guides and FAQs for Week 1 Note : The bot is limited to Week 1 content only in this MVP version.","title":"What content does the bot have access to?"},{"location":"faq/#how-accurate-are-the-bots-responses","text":"The bot aims for 80-90% accuracy on common Week 1 questions. Accuracy depends on: - Quality of the source content - Clarity of the user's question - Availability of relevant information in the knowledge base","title":"How accurate are the bot's responses?"},{"location":"faq/#can-the-bot-provide-medical-advice","text":"No. The bot provides educational information based on program content but cannot: - Diagnose medical conditions - Provide personalized medical advice - Replace consultation with healthcare professionals - Make treatment recommendations Always consult with qualified healthcare providers for medical concerns.","title":"Can the bot provide medical advice?"},{"location":"faq/#usage-questions","text":"","title":"Usage Questions"},{"location":"faq/#how-do-i-ask-the-bot-a-question","text":"There are several ways to interact with the bot: In channels : Mention the bot with your question @gutless-assistant What foods should I avoid in Week 1? Direct messages : Send a direct message to the bot Can you explain the elimination protocol? Thread replies : The bot can continue conversations in threads","title":"How do I ask the bot a question?"},{"location":"faq/#what-types-of-questions-can-i-ask","text":"You can ask about: - Protocols : \"What's the Week 1 morning routine?\" - Foods : \"What can I eat during the elimination phase?\" - Symptoms : \"What symptoms are normal in Week 1?\" - Procedures : \"How do I prepare for Week 1?\" - Troubleshooting : \"I'm having issues with [specific problem]\" - Clarifications : \"Can you explain [specific concept] better?\"","title":"What types of questions can I ask?"},{"location":"faq/#why-doesnt-the-bot-understand-my-question","text":"Common reasons include: - Too vague : \"Help me\" vs. \"What foods should I avoid in Week 1?\" - Outside scope : Questions about Week 2+ content - Unclear phrasing : Try rephrasing more specifically - Missing context : Include relevant details","title":"Why doesn't the bot understand my question?"},{"location":"faq/#how-long-does-it-take-to-get-a-response","text":"Typical response time : 2-5 seconds Complex questions : 5-10 seconds High load periods : Up to 30 seconds If no response after 30 seconds, try asking again.","title":"How long does it take to get a response?"},{"location":"faq/#can-i-ask-follow-up-questions","text":"Yes! The bot can handle follow-up questions in the same conversation thread. For example: User: What foods are eliminated in Week 1? Bot: [Lists eliminated foods] User: Why are these foods eliminated? Bot: [Explains the reasoning]","title":"Can I ask follow-up questions?"},{"location":"faq/#technical-questions","text":"","title":"Technical Questions"},{"location":"faq/#what-technology-powers-the-bot","text":"The bot uses: - AI Model : OpenAI GPT-4o for answer generation - Embeddings : OpenAI text-embedding-ada-002 for semantic search - Vector Database : Pinecone for content storage and retrieval - Platform : Slack Bolt SDK for Python - Transcription : OpenAI Whisper for audio processing","title":"What technology powers the bot?"},{"location":"faq/#how-does-the-bot-find-relevant-information","text":"The process involves: 1. Query embedding : Your question is converted to a vector 2. Similarity search : The vector database finds similar content 3. Context assembly : Relevant chunks are combined 4. Answer generation : GPT-4o creates an answer using the context 5. Source linking : References are added to the response","title":"How does the bot find relevant information?"},{"location":"faq/#is-my-data-private-and-secure","text":"Privacy measures : - Questions and responses are logged for improvement purposes only - No personal health data is stored beyond what you share in questions - All API communications use HTTPS encryption - Data is handled according to privacy best practices What's stored : - Your questions and bot responses (for analytics) - Slack user IDs (for logging purposes) What's NOT stored : - Private Slack conversations outside bot interactions - Personal files or attachments - Sensitive personal information","title":"Is my data private and secure?"},{"location":"faq/#can-i-use-the-bot-offline","text":"No, the bot requires internet connectivity to: - Access OpenAI APIs - Query the Pinecone vector database - Communicate with Slack","title":"Can I use the bot offline?"},{"location":"faq/#content-and-accuracy-questions","text":"","title":"Content and Accuracy Questions"},{"location":"faq/#what-if-the-bot-gives-incorrect-information","text":"If you notice incorrect information: 1. Cross-reference with original program materials 2. Report the issue with specific details 3. Ask for clarification or rephrase your question 4. Consult program coaches for verification","title":"What if the bot gives incorrect information?"},{"location":"faq/#how-often-is-the-content-updated","text":"Currently, the bot contains Week 1 content that was ingested during setup. Content updates require: - Manual re-ingestion of new materials - System administrator intervention - Potential downtime during updates","title":"How often is the content updated?"},{"location":"faq/#can-the-bot-access-new-week-1-materials","text":"Not automatically. New materials must be: - Processed through the content ingestion pipeline - Converted to embeddings - Added to the vector database This requires technical intervention.","title":"Can the bot access new Week 1 materials?"},{"location":"faq/#why-does-the-bot-sometimes-say-i-dont-know","text":"This happens when: - The question is outside the Week 1 scope - No relevant content is found in the database - The confidence score is too low - The question is too ambiguous","title":"Why does the bot sometimes say \"I don't know\"?"},{"location":"faq/#troubleshooting-questions","text":"","title":"Troubleshooting Questions"},{"location":"faq/#the-bot-isnt-responding-what-should-i-do","text":"Check bot status : Is it showing as online in Slack? Try rephrasing : Make your question more specific Wait and retry : There might be temporary issues Check spelling : Ensure you're mentioning the correct bot name Try direct message : Sometimes channel mentions fail","title":"The bot isn't responding. What should I do?"},{"location":"faq/#the-bot-gave-an-error-message-what-does-it-mean","text":"Error Message Meaning Solution \"I'm having trouble processing your request\" General system error Try again in a few minutes \"No relevant content found\" No matching information Rephrase or ask about Week 1 topics \"Service temporarily unavailable\" API issues Wait and retry \"I can only answer questions about Week 1\" Out of scope Ask about Week 1 content only","title":"The bot gave an error message. What does it mean?"},{"location":"faq/#the-response-seems-incomplete-or-cut-off-why","text":"This can happen due to: - Token limits : Very long responses may be truncated - Network issues : Connection problems during response - Rate limiting : API limits reached Solution : Ask for specific parts of the information you need.","title":"The response seems incomplete or cut off. Why?"},{"location":"faq/#can-i-get-more-detailed-information","text":"Yes! Try: - Ask for elaboration : \"Can you explain that in more detail?\" - Request specific aspects : \"What are the specific steps for [process]?\" - Ask for examples : \"Can you give me examples of [concept]?\" - Request sources : \"Where in the video is this discussed?\"","title":"Can I get more detailed information?"},{"location":"faq/#administrative-questions","text":"","title":"Administrative Questions"},{"location":"faq/#who-can-use-the-bot","text":"Access is typically limited to: - Members of the designated Slack workspace - Gutless program participants - Authorized coaches and staff","title":"Who can use the bot?"},{"location":"faq/#can-i-add-the-bot-to-other-channels","text":"This depends on: - Bot permissions in your workspace - Channel privacy settings - Administrator policies Try /invite @gutless-assistant in the desired channel.","title":"Can I add the bot to other channels?"},{"location":"faq/#how-do-i-report-bugs-or-suggest-improvements","text":"To report issues: 1. Document the problem : What happened vs. what you expected 2. Include context : Your exact question and the bot's response 3. Note timing : When did the issue occur 4. Contact administrators : Through designated support channels","title":"How do I report bugs or suggest improvements?"},{"location":"faq/#can-the-bot-be-customized-for-our-specific-needs","text":"Potential customizations include: - Content scope : Adding more weeks or programs - Response style : Adjusting tone or format - Integration : Connecting to other systems - Features : Adding new capabilities Customizations require development work and should be discussed with the technical team.","title":"Can the bot be customized for our specific needs?"},{"location":"faq/#performance-questions","text":"","title":"Performance Questions"},{"location":"faq/#why-are-responses-sometimes-slow","text":"Response time can be affected by: - Question complexity : More complex queries take longer - API load : High usage of OpenAI or Pinecone services - Network conditions : Internet connectivity issues - System load : Multiple concurrent users","title":"Why are responses sometimes slow?"},{"location":"faq/#can-i-make-the-bot-respond-faster","text":"Tips for faster responses : - Ask specific, focused questions - Avoid very long or complex queries - Use clear, simple language - Ask one question at a time","title":"Can I make the bot respond faster?"},{"location":"faq/#does-the-bot-work-better-at-certain-times","text":"Performance is generally consistent, but may be slower during: - Peak usage hours - API maintenance windows - High network traffic periods","title":"Does the bot work better at certain times?"},{"location":"faq/#future-development-questions","text":"","title":"Future Development Questions"},{"location":"faq/#will-the-bot-support-more-content-in-the-future","text":"Potential future enhancements: - Week 2+ content : Expanding beyond Week 1 - Multiple programs : Supporting other coaching programs - Interactive features : More sophisticated interactions - Integrations : Connecting to other tools and platforms","title":"Will the bot support more content in the future?"},{"location":"faq/#can-the-bot-learn-from-interactions","text":"Currently, the bot: - Logs interactions for analysis - Does not learn automatically from conversations - Requires manual updates to improve responses Future versions might include: - Automatic learning capabilities - Feedback-based improvements - Adaptive response generation","title":"Can the bot learn from interactions?"},{"location":"faq/#how-can-i-stay-updated-on-new-features","text":"Stay informed through: - Slack announcements in your workspace - Program communication channels - Documentation updates - Release notes and changelogs","title":"How can I stay updated on new features?"},{"location":"faq/#getting-more-help","text":"","title":"Getting More Help"},{"location":"faq/#where-can-i-find-more-detailed-documentation","text":"Installation Guide Usage Guide Troubleshooting Guide API Reference Architecture Overview","title":"Where can I find more detailed documentation?"},{"location":"faq/#who-should-i-contact-for-support","text":"For usage questions : Ask in your Slack workspace or consult this FAQ For technical issues : Contact your system administrator or technical support team For content questions : Consult with program coaches or refer to original materials For feature requests : Submit through designated feedback channels","title":"Who should I contact for support?"},{"location":"faq/#is-there-a-user-community-or-forum","text":"Check with your program administrators about: - Dedicated Slack channels for bot discussions - User feedback groups - Community forums or resources - Regular Q&A sessions This FAQ is regularly updated. If you have questions not covered here, please reach out through appropriate support channels.","title":"Is there a user community or forum?"},{"location":"installation/","text":"Installation Guide \u00b6 This guide will walk you through setting up the Renesis AI Assistant on your local machine or server. Prerequisites \u00b6 Python 3.8 or higher pip (Python package installer) Git Access to the following services: OpenAI API (for GPT-4o and embeddings) Pinecone (for vector database) Slack workspace with bot creation permissions Step 1: Clone the Repository \u00b6 git clone <repository-url> cd gutless-ai-assistant Step 2: Create Virtual Environment \u00b6 # Create virtual environment python -m venv venv # Activate virtual environment # On Windows: venv \\S cripts \\a ctivate # On macOS/Linux: source venv/bin/activate Step 3: Install Dependencies \u00b6 pip install -r requirements.txt Step 4: Environment Configuration \u00b6 Copy the example environment file: cp .env.example .env Edit the .env file with your API keys and configuration: # OpenAI Configuration OPENAI_API_KEY=your_openai_api_key_here OPENAI_MODEL=gpt-4o OPENAI_EMBEDDING_MODEL=text-embedding-ada-002 # Pinecone Configuration PINECONE_API_KEY=your_pinecone_api_key_here PINECONE_ENVIRONMENT=your_pinecone_environment PINECONE_INDEX_NAME=gutless-assistant # Slack Configuration SLACK_BOT_TOKEN=xoxb-your-slack-bot-token SLACK_SIGNING_SECRET=your_slack_signing_secret SLACK_APP_TOKEN=xapp-your-slack-app-token # Application Configuration LOG_LEVEL=INFO DEBUG=False Step 5: Set Up External Services \u00b6 OpenAI API \u00b6 Visit OpenAI Platform Create an account or sign in Generate an API key Add the key to your .env file Pinecone \u00b6 Visit Pinecone Create an account Create a new index with the following settings: Dimensions: 1536 (for OpenAI embeddings) Metric: cosine Index name: gutless-assistant Get your API key and environment Add them to your .env file Slack App \u00b6 Visit Slack API Create a new app Configure the following: OAuth & Permissions : Add bot token scopes: app_mentions:read chat:write im:read im:write Event Subscriptions : Enable and add: app_mention message.im Socket Mode : Enable for development Install the app to your workspace Copy the tokens to your .env file Step 6: Initialize the Database \u00b6 # Run the data ingestion script to set up initial content python scripts/ingest_data.py Step 7: Run the Application \u00b6 # Start the Slack bot python src/bot.py Verification \u00b6 Check that the bot appears online in your Slack workspace Send a direct message to the bot or mention it in a channel Verify that it responds appropriately Troubleshooting \u00b6 If you encounter issues during installation: Python Version : Ensure you're using Python 3.8+ Dependencies : Try upgrading pip: pip install --upgrade pip API Keys : Verify all API keys are correct and have proper permissions Network : Check firewall settings if running on a server For more detailed troubleshooting, see our Troubleshooting Guide . Next Steps \u00b6 Configuration Guide Usage Guide","title":"Installation"},{"location":"installation/#installation-guide","text":"This guide will walk you through setting up the Renesis AI Assistant on your local machine or server.","title":"Installation Guide"},{"location":"installation/#prerequisites","text":"Python 3.8 or higher pip (Python package installer) Git Access to the following services: OpenAI API (for GPT-4o and embeddings) Pinecone (for vector database) Slack workspace with bot creation permissions","title":"Prerequisites"},{"location":"installation/#step-1-clone-the-repository","text":"git clone <repository-url> cd gutless-ai-assistant","title":"Step 1: Clone the Repository"},{"location":"installation/#step-2-create-virtual-environment","text":"# Create virtual environment python -m venv venv # Activate virtual environment # On Windows: venv \\S cripts \\a ctivate # On macOS/Linux: source venv/bin/activate","title":"Step 2: Create Virtual Environment"},{"location":"installation/#step-3-install-dependencies","text":"pip install -r requirements.txt","title":"Step 3: Install Dependencies"},{"location":"installation/#step-4-environment-configuration","text":"Copy the example environment file: cp .env.example .env Edit the .env file with your API keys and configuration: # OpenAI Configuration OPENAI_API_KEY=your_openai_api_key_here OPENAI_MODEL=gpt-4o OPENAI_EMBEDDING_MODEL=text-embedding-ada-002 # Pinecone Configuration PINECONE_API_KEY=your_pinecone_api_key_here PINECONE_ENVIRONMENT=your_pinecone_environment PINECONE_INDEX_NAME=gutless-assistant # Slack Configuration SLACK_BOT_TOKEN=xoxb-your-slack-bot-token SLACK_SIGNING_SECRET=your_slack_signing_secret SLACK_APP_TOKEN=xapp-your-slack-app-token # Application Configuration LOG_LEVEL=INFO DEBUG=False","title":"Step 4: Environment Configuration"},{"location":"installation/#step-5-set-up-external-services","text":"","title":"Step 5: Set Up External Services"},{"location":"installation/#openai-api","text":"Visit OpenAI Platform Create an account or sign in Generate an API key Add the key to your .env file","title":"OpenAI API"},{"location":"installation/#pinecone","text":"Visit Pinecone Create an account Create a new index with the following settings: Dimensions: 1536 (for OpenAI embeddings) Metric: cosine Index name: gutless-assistant Get your API key and environment Add them to your .env file","title":"Pinecone"},{"location":"installation/#slack-app","text":"Visit Slack API Create a new app Configure the following: OAuth & Permissions : Add bot token scopes: app_mentions:read chat:write im:read im:write Event Subscriptions : Enable and add: app_mention message.im Socket Mode : Enable for development Install the app to your workspace Copy the tokens to your .env file","title":"Slack App"},{"location":"installation/#step-6-initialize-the-database","text":"# Run the data ingestion script to set up initial content python scripts/ingest_data.py","title":"Step 6: Initialize the Database"},{"location":"installation/#step-7-run-the-application","text":"# Start the Slack bot python src/bot.py","title":"Step 7: Run the Application"},{"location":"installation/#verification","text":"Check that the bot appears online in your Slack workspace Send a direct message to the bot or mention it in a channel Verify that it responds appropriately","title":"Verification"},{"location":"installation/#troubleshooting","text":"If you encounter issues during installation: Python Version : Ensure you're using Python 3.8+ Dependencies : Try upgrading pip: pip install --upgrade pip API Keys : Verify all API keys are correct and have proper permissions Network : Check firewall settings if running on a server For more detailed troubleshooting, see our Troubleshooting Guide .","title":"Troubleshooting"},{"location":"installation/#next-steps","text":"Configuration Guide Usage Guide","title":"Next Steps"},{"location":"troubleshooting/","text":"Troubleshooting Guide \u00b6 This guide helps you diagnose and resolve common issues with the Renesis AI Assistant. Quick Diagnostics \u00b6 Health Check Commands \u00b6 Run these commands to quickly check system health: # Test configuration loading python -c \"from config.settings import settings; print('\u2705 Configuration loaded')\" # Test API connections python scripts/test_connections.py # Check bot status python -c \"from src.bot import SlackBot; print('\u2705 Bot module imports successfully')\" Common Status Indicators \u00b6 Status Meaning Action \u2705 Bot online in Slack Working correctly None needed \u26a0\ufe0f Bot appears offline Connection issue Check tokens and network \u274c Bot not responding Critical error Check logs and restart \ud83d\udd04 Slow responses Performance issue Check API rate limits Installation Issues \u00b6 Python Version Problems \u00b6 Problem : SyntaxError or compatibility issues Solution : # Check Python version python --version # Should be 3.8 or higher # If using wrong version, create virtual environment with correct Python python3.8 -m venv venv # or conda create -n gutless-assistant python = 3 .8 Dependency Installation Failures \u00b6 Problem : pip install fails with errors Solutions : Upgrade pip : pip install --upgrade pip Clear pip cache : pip cache purge Install with verbose output : pip install -r requirements.txt -v Platform-specific issues : # Windows: Install Visual C++ Build Tools # macOS: Install Xcode command line tools xcode-select --install # Linux: Install build essentials sudo apt-get install build-essential Virtual Environment Issues \u00b6 Problem : Packages not found or wrong versions Solution : # Deactivate and recreate virtual environment deactivate rm -rf venv # or rmdir /s venv on Windows python -m venv venv source venv/bin/activate # or venv\\Scripts\\activate on Windows pip install -r requirements.txt Configuration Issues \u00b6 Environment Variables Not Loading \u00b6 Problem : KeyError or None values for environment variables Diagnosis : # Check if .env file exists ls -la .env # Check environment variable loading python -c \"import os; from dotenv import load_dotenv; load_dotenv(); print(os.getenv('OPENAI_API_KEY')[:10] if os.getenv('OPENAI_API_KEY') else 'Not found')\" Solutions : Create .env file : cp .env.example .env # Edit .env with your actual values Check file format : # Correct format (no spaces around =) OPENAI_API_KEY=sk-your-key-here # Incorrect format OPENAI_API_KEY = sk-your-key-here Verify file location : # .env should be in project root gutless-ai-assistant/ \u251c\u2500\u2500 .env \u2190 Here \u251c\u2500\u2500 src/ \u2514\u2500\u2500 docs/ Invalid API Keys \u00b6 Problem : Authentication errors from external APIs Diagnosis : # Test OpenAI key curl -H \"Authorization: Bearer $OPENAI_API_KEY \" https://api.openai.com/v1/models # Test Pinecone key python -c \"import pinecone; pinecone.init(api_key='your-key', environment='your-env'); print('\u2705 Pinecone connected')\" Solutions : Regenerate API keys from respective platforms Check key format : OpenAI: sk-... (starts with sk-) Pinecone: UUID format Slack Bot: xoxb-... Slack App: xapp-... Verify permissions on API keys Slack Integration Issues \u00b6 Bot Not Responding \u00b6 Problem : Bot appears online but doesn't respond to messages Diagnosis : # Check bot logs tail -f logs/app.log # Test bot locally python src/bot.py Solutions : Check Event Subscriptions : Go to Slack App settings Verify app_mention and message.im events are enabled Check Request URL is correct Verify Bot Permissions : app_mentions:read chat:write im:read im:write Socket Mode Issues : # Enable Socket Mode in Slack app settings # Ensure SLACK_APP_TOKEN is set # Check if port 3000 is available Bot Responds with Errors \u00b6 Problem : Bot sends error messages instead of answers Common Error Messages : Error Message Cause Solution \"I'm having trouble processing your request\" General error Check logs for specific error \"No relevant content found\" Empty search results Check content ingestion \"Service temporarily unavailable\" API rate limit or outage Wait and retry \"Invalid query format\" Query preprocessing error Rephrase question Permission Denied Errors \u00b6 Problem : Bot can't send messages or access channels Solution : 1. Reinstall bot to workspace 2. Check channel permissions : - Invite bot to private channels - Verify bot has write permissions 3. Update OAuth scopes if needed API Integration Issues \u00b6 OpenAI API Problems \u00b6 Rate Limit Exceeded : Error: Rate limit exceeded Solutions : - Implement exponential backoff (already included) - Reduce request frequency - Upgrade OpenAI plan - Check for infinite loops in code Invalid Model Access : Error: The model 'gpt-4o' does not exist Solutions : - Verify model name in configuration - Check OpenAI account has access to GPT-4 - Use alternative model (gpt-3.5-turbo) Token Limit Exceeded : Error: This model's maximum context length is X tokens Solutions : - Reduce context size in queries - Implement context truncation - Split large queries Pinecone Issues \u00b6 Index Not Found : Error: Index 'gutless-assistant' not found Solutions : 1. Create index : import pinecone pinecone . init ( api_key = \"your-key\" , environment = \"your-env\" ) pinecone . create_index ( name = \"gutless-assistant\" , dimension = 1536 , metric = \"cosine\" ) Check index name in configuration Connection Timeout : Error: Connection timeout Solutions : - Check network connectivity - Verify Pinecone environment setting - Implement retry logic Quota Exceeded : Error: Quota exceeded Solutions : - Upgrade Pinecone plan - Optimize vector storage - Implement batch operations Content Ingestion Issues \u00b6 Transcription Failures \u00b6 Problem : Audio/video files not transcribing Diagnosis : # Check file format file audio_file.mp3 # Check file size ls -lh audio_file.mp3 # Test transcription manually python -c \"from src.content_ingestion.transcribe import TranscriptionService; ts = TranscriptionService(); result = ts.transcribe_file('path/to/file')\" Solutions : Supported formats : mp3, wav, m4a, mp4 File size limit : 25MB for Whisper Audio quality : Ensure clear audio File path : Use absolute paths PDF Processing Issues \u00b6 Problem : PDF content not extracting properly Common Issues : - Scanned PDFs (image-based) - Password-protected PDFs - Corrupted files - Complex layouts Solutions : # Test PDF extraction from src.content_ingestion.pdf_parser import PDFParser parser = PDFParser () content = parser . extract_text ( \"path/to/file.pdf\" ) print ( content . text [: 500 ]) # First 500 characters Embedding Generation Failures \u00b6 Problem : Embeddings not generating for content Diagnosis : # Test embedding service from src.embedding_service import EmbeddingService service = EmbeddingService ( api_key = \"your-key\" ) vector = service . generate_embedding ( \"test text\" ) print ( f \"Embedding dimension: { len ( vector ) } \" ) Solutions : - Check OpenAI API key - Verify text is not empty - Handle special characters - Check text length limits Performance Issues \u00b6 Slow Response Times \u00b6 Problem : Bot takes too long to respond Diagnosis : # Check response times in logs grep \"processing_time\" logs/app.log # Monitor API response times grep \"openai_response_time\" logs/app.log grep \"pinecone_response_time\" logs/app.log Solutions : Optimize vector search : Reduce top_k value Add metadata filters Use smaller embedding dimensions Implement caching : Cache frequent queries Cache embeddings Use Redis for session storage Optimize content chunks : Reduce chunk size Improve chunk quality Remove irrelevant content Memory Issues \u00b6 Problem : High memory usage or out-of-memory errors Solutions : Batch processing : # Process in smaller batches for batch in chunks ( large_list , batch_size = 100 ): process_batch ( batch ) Memory monitoring : import psutil print ( f \"Memory usage: { psutil . virtual_memory () . percent } %\" ) Garbage collection : import gc gc . collect () Logging and Debugging \u00b6 Enable Debug Logging \u00b6 # In .env file LOG_LEVEL = DEBUG DEBUG = True # Or programmatically import logging logging . getLogger () . setLevel ( logging . DEBUG ) Log File Locations \u00b6 # Application logs tail -f logs/app.log # Error logs tail -f logs/error.log # Slack events tail -f logs/slack.log Debug Commands \u00b6 # Test individual components python -m src.embedding_service python -m src.pinecone_service python -m src.core_logic # Run with debug output python -u src/bot.py 2 > & 1 | tee debug.log Getting Help \u00b6 Before Asking for Help \u00b6 Check logs for specific error messages Search this guide for similar issues Test individual components to isolate the problem Gather system information : Python version Operating system Package versions Error messages Information to Include \u00b6 When reporting issues, include: # System information python --version pip list | grep -E \"(openai|pinecone|slack)\" # Error logs (last 50 lines) tail -50 logs/app.log # Configuration (without sensitive data) env | grep -E \"(OPENAI|PINECONE|SLACK)\" | sed 's/=.*/=****/' Emergency Procedures \u00b6 If bot is completely unresponsive : Restart the application : # Stop current process Ctrl+C # Restart python src/bot.py Reset to known good state : # Pull latest code git pull origin main # Reinstall dependencies pip install -r requirements.txt --force-reinstall # Clear cache rm -rf __pycache__ src/__pycache__ Fallback configuration : # Use basic settings OPENAI_MODEL=gpt-3.5-turbo PINECONE_TOP_K=3 LOG_LEVEL=INFO Next Steps \u00b6 FAQ API Reference Configuration Guide","title":"Troubleshooting"},{"location":"troubleshooting/#troubleshooting-guide","text":"This guide helps you diagnose and resolve common issues with the Renesis AI Assistant.","title":"Troubleshooting Guide"},{"location":"troubleshooting/#quick-diagnostics","text":"","title":"Quick Diagnostics"},{"location":"troubleshooting/#health-check-commands","text":"Run these commands to quickly check system health: # Test configuration loading python -c \"from config.settings import settings; print('\u2705 Configuration loaded')\" # Test API connections python scripts/test_connections.py # Check bot status python -c \"from src.bot import SlackBot; print('\u2705 Bot module imports successfully')\"","title":"Health Check Commands"},{"location":"troubleshooting/#common-status-indicators","text":"Status Meaning Action \u2705 Bot online in Slack Working correctly None needed \u26a0\ufe0f Bot appears offline Connection issue Check tokens and network \u274c Bot not responding Critical error Check logs and restart \ud83d\udd04 Slow responses Performance issue Check API rate limits","title":"Common Status Indicators"},{"location":"troubleshooting/#installation-issues","text":"","title":"Installation Issues"},{"location":"troubleshooting/#python-version-problems","text":"Problem : SyntaxError or compatibility issues Solution : # Check Python version python --version # Should be 3.8 or higher # If using wrong version, create virtual environment with correct Python python3.8 -m venv venv # or conda create -n gutless-assistant python = 3 .8","title":"Python Version Problems"},{"location":"troubleshooting/#dependency-installation-failures","text":"Problem : pip install fails with errors Solutions : Upgrade pip : pip install --upgrade pip Clear pip cache : pip cache purge Install with verbose output : pip install -r requirements.txt -v Platform-specific issues : # Windows: Install Visual C++ Build Tools # macOS: Install Xcode command line tools xcode-select --install # Linux: Install build essentials sudo apt-get install build-essential","title":"Dependency Installation Failures"},{"location":"troubleshooting/#virtual-environment-issues","text":"Problem : Packages not found or wrong versions Solution : # Deactivate and recreate virtual environment deactivate rm -rf venv # or rmdir /s venv on Windows python -m venv venv source venv/bin/activate # or venv\\Scripts\\activate on Windows pip install -r requirements.txt","title":"Virtual Environment Issues"},{"location":"troubleshooting/#configuration-issues","text":"","title":"Configuration Issues"},{"location":"troubleshooting/#environment-variables-not-loading","text":"Problem : KeyError or None values for environment variables Diagnosis : # Check if .env file exists ls -la .env # Check environment variable loading python -c \"import os; from dotenv import load_dotenv; load_dotenv(); print(os.getenv('OPENAI_API_KEY')[:10] if os.getenv('OPENAI_API_KEY') else 'Not found')\" Solutions : Create .env file : cp .env.example .env # Edit .env with your actual values Check file format : # Correct format (no spaces around =) OPENAI_API_KEY=sk-your-key-here # Incorrect format OPENAI_API_KEY = sk-your-key-here Verify file location : # .env should be in project root gutless-ai-assistant/ \u251c\u2500\u2500 .env \u2190 Here \u251c\u2500\u2500 src/ \u2514\u2500\u2500 docs/","title":"Environment Variables Not Loading"},{"location":"troubleshooting/#invalid-api-keys","text":"Problem : Authentication errors from external APIs Diagnosis : # Test OpenAI key curl -H \"Authorization: Bearer $OPENAI_API_KEY \" https://api.openai.com/v1/models # Test Pinecone key python -c \"import pinecone; pinecone.init(api_key='your-key', environment='your-env'); print('\u2705 Pinecone connected')\" Solutions : Regenerate API keys from respective platforms Check key format : OpenAI: sk-... (starts with sk-) Pinecone: UUID format Slack Bot: xoxb-... Slack App: xapp-... Verify permissions on API keys","title":"Invalid API Keys"},{"location":"troubleshooting/#slack-integration-issues","text":"","title":"Slack Integration Issues"},{"location":"troubleshooting/#bot-not-responding","text":"Problem : Bot appears online but doesn't respond to messages Diagnosis : # Check bot logs tail -f logs/app.log # Test bot locally python src/bot.py Solutions : Check Event Subscriptions : Go to Slack App settings Verify app_mention and message.im events are enabled Check Request URL is correct Verify Bot Permissions : app_mentions:read chat:write im:read im:write Socket Mode Issues : # Enable Socket Mode in Slack app settings # Ensure SLACK_APP_TOKEN is set # Check if port 3000 is available","title":"Bot Not Responding"},{"location":"troubleshooting/#bot-responds-with-errors","text":"Problem : Bot sends error messages instead of answers Common Error Messages : Error Message Cause Solution \"I'm having trouble processing your request\" General error Check logs for specific error \"No relevant content found\" Empty search results Check content ingestion \"Service temporarily unavailable\" API rate limit or outage Wait and retry \"Invalid query format\" Query preprocessing error Rephrase question","title":"Bot Responds with Errors"},{"location":"troubleshooting/#permission-denied-errors","text":"Problem : Bot can't send messages or access channels Solution : 1. Reinstall bot to workspace 2. Check channel permissions : - Invite bot to private channels - Verify bot has write permissions 3. Update OAuth scopes if needed","title":"Permission Denied Errors"},{"location":"troubleshooting/#api-integration-issues","text":"","title":"API Integration Issues"},{"location":"troubleshooting/#openai-api-problems","text":"Rate Limit Exceeded : Error: Rate limit exceeded Solutions : - Implement exponential backoff (already included) - Reduce request frequency - Upgrade OpenAI plan - Check for infinite loops in code Invalid Model Access : Error: The model 'gpt-4o' does not exist Solutions : - Verify model name in configuration - Check OpenAI account has access to GPT-4 - Use alternative model (gpt-3.5-turbo) Token Limit Exceeded : Error: This model's maximum context length is X tokens Solutions : - Reduce context size in queries - Implement context truncation - Split large queries","title":"OpenAI API Problems"},{"location":"troubleshooting/#pinecone-issues","text":"Index Not Found : Error: Index 'gutless-assistant' not found Solutions : 1. Create index : import pinecone pinecone . init ( api_key = \"your-key\" , environment = \"your-env\" ) pinecone . create_index ( name = \"gutless-assistant\" , dimension = 1536 , metric = \"cosine\" ) Check index name in configuration Connection Timeout : Error: Connection timeout Solutions : - Check network connectivity - Verify Pinecone environment setting - Implement retry logic Quota Exceeded : Error: Quota exceeded Solutions : - Upgrade Pinecone plan - Optimize vector storage - Implement batch operations","title":"Pinecone Issues"},{"location":"troubleshooting/#content-ingestion-issues","text":"","title":"Content Ingestion Issues"},{"location":"troubleshooting/#transcription-failures","text":"Problem : Audio/video files not transcribing Diagnosis : # Check file format file audio_file.mp3 # Check file size ls -lh audio_file.mp3 # Test transcription manually python -c \"from src.content_ingestion.transcribe import TranscriptionService; ts = TranscriptionService(); result = ts.transcribe_file('path/to/file')\" Solutions : Supported formats : mp3, wav, m4a, mp4 File size limit : 25MB for Whisper Audio quality : Ensure clear audio File path : Use absolute paths","title":"Transcription Failures"},{"location":"troubleshooting/#pdf-processing-issues","text":"Problem : PDF content not extracting properly Common Issues : - Scanned PDFs (image-based) - Password-protected PDFs - Corrupted files - Complex layouts Solutions : # Test PDF extraction from src.content_ingestion.pdf_parser import PDFParser parser = PDFParser () content = parser . extract_text ( \"path/to/file.pdf\" ) print ( content . text [: 500 ]) # First 500 characters","title":"PDF Processing Issues"},{"location":"troubleshooting/#embedding-generation-failures","text":"Problem : Embeddings not generating for content Diagnosis : # Test embedding service from src.embedding_service import EmbeddingService service = EmbeddingService ( api_key = \"your-key\" ) vector = service . generate_embedding ( \"test text\" ) print ( f \"Embedding dimension: { len ( vector ) } \" ) Solutions : - Check OpenAI API key - Verify text is not empty - Handle special characters - Check text length limits","title":"Embedding Generation Failures"},{"location":"troubleshooting/#performance-issues","text":"","title":"Performance Issues"},{"location":"troubleshooting/#slow-response-times","text":"Problem : Bot takes too long to respond Diagnosis : # Check response times in logs grep \"processing_time\" logs/app.log # Monitor API response times grep \"openai_response_time\" logs/app.log grep \"pinecone_response_time\" logs/app.log Solutions : Optimize vector search : Reduce top_k value Add metadata filters Use smaller embedding dimensions Implement caching : Cache frequent queries Cache embeddings Use Redis for session storage Optimize content chunks : Reduce chunk size Improve chunk quality Remove irrelevant content","title":"Slow Response Times"},{"location":"troubleshooting/#memory-issues","text":"Problem : High memory usage or out-of-memory errors Solutions : Batch processing : # Process in smaller batches for batch in chunks ( large_list , batch_size = 100 ): process_batch ( batch ) Memory monitoring : import psutil print ( f \"Memory usage: { psutil . virtual_memory () . percent } %\" ) Garbage collection : import gc gc . collect ()","title":"Memory Issues"},{"location":"troubleshooting/#logging-and-debugging","text":"","title":"Logging and Debugging"},{"location":"troubleshooting/#enable-debug-logging","text":"# In .env file LOG_LEVEL = DEBUG DEBUG = True # Or programmatically import logging logging . getLogger () . setLevel ( logging . DEBUG )","title":"Enable Debug Logging"},{"location":"troubleshooting/#log-file-locations","text":"# Application logs tail -f logs/app.log # Error logs tail -f logs/error.log # Slack events tail -f logs/slack.log","title":"Log File Locations"},{"location":"troubleshooting/#debug-commands","text":"# Test individual components python -m src.embedding_service python -m src.pinecone_service python -m src.core_logic # Run with debug output python -u src/bot.py 2 > & 1 | tee debug.log","title":"Debug Commands"},{"location":"troubleshooting/#getting-help","text":"","title":"Getting Help"},{"location":"troubleshooting/#before-asking-for-help","text":"Check logs for specific error messages Search this guide for similar issues Test individual components to isolate the problem Gather system information : Python version Operating system Package versions Error messages","title":"Before Asking for Help"},{"location":"troubleshooting/#information-to-include","text":"When reporting issues, include: # System information python --version pip list | grep -E \"(openai|pinecone|slack)\" # Error logs (last 50 lines) tail -50 logs/app.log # Configuration (without sensitive data) env | grep -E \"(OPENAI|PINECONE|SLACK)\" | sed 's/=.*/=****/'","title":"Information to Include"},{"location":"troubleshooting/#emergency-procedures","text":"If bot is completely unresponsive : Restart the application : # Stop current process Ctrl+C # Restart python src/bot.py Reset to known good state : # Pull latest code git pull origin main # Reinstall dependencies pip install -r requirements.txt --force-reinstall # Clear cache rm -rf __pycache__ src/__pycache__ Fallback configuration : # Use basic settings OPENAI_MODEL=gpt-3.5-turbo PINECONE_TOP_K=3 LOG_LEVEL=INFO","title":"Emergency Procedures"},{"location":"troubleshooting/#next-steps","text":"FAQ API Reference Configuration Guide","title":"Next Steps"},{"location":"usage/","text":"Usage Guide \u00b6 This guide explains how to use the Renesis AI Assistant once it's installed and configured. Getting Started \u00b6 Inviting the Bot to Channels \u00b6 In your Slack workspace, go to the channel where you want to use the bot Type /invite @gutless-assistant (replace with your bot's name) The bot will join the channel and be ready to answer questions Direct Messages \u00b6 You can also send direct messages to the bot: Click on the bot's name in your Slack workspace Start a direct message conversation Ask your questions directly How to Ask Questions \u00b6 Mentioning the Bot \u00b6 In channels, mention the bot to get its attention: @gutless-assistant What are the key principles covered in Week 1? Direct Questions \u00b6 In direct messages, you can ask questions without mentioning: Can you explain the gut health fundamentals from the first week? Question Types \u00b6 The bot can handle various types of questions about Week 1 content: Content-Specific Questions \u00b6 @gutless-assistant What foods should I avoid in Week 1? @gutless-assistant How long should I follow the Week 1 protocol? @gutless-assistant What are the symptoms I might experience? Clarification Questions \u00b6 @gutless-assistant Can you explain more about [specific topic]? @gutless-assistant What did the coach mean when they said [quote]? @gutless-assistant I didn't understand the part about [topic] Reference Questions \u00b6 @gutless-assistant Where can I find the Week 1 meal plan? @gutless-assistant What time in the video was this discussed? @gutless-assistant Is there a PDF with this information? Understanding Bot Responses \u00b6 Response Format \u00b6 The bot provides structured responses that include: Direct Answer : A clear, concise answer to your question Source References : Links to relevant video timestamps or PDF sections Additional Context : Related information that might be helpful Example Response \u00b6 \ud83e\udd16 **Renesis AI Assistant** Based on the Week 1 content, here are the key foods to avoid: \u2022 Processed foods and refined sugars \u2022 Gluten-containing grains \u2022 Dairy products (except for specific exceptions mentioned) \u2022 Inflammatory oils like vegetable and seed oils \ud83d\udcf9 **Video Reference**: [Week 1 Coaching Call - 15:30-18:45](link-to-video) \ud83d\udcc4 **PDF Reference**: Week 1 Food Guide, Page 3 \ud83d\udca1 **Additional Info**: The coach also mentioned that individual tolerance may vary, so pay attention to your body's responses. Source Links \u00b6 The bot provides clickable links that take you directly to: - Video timestamps : Exact moments in coaching calls where topics are discussed - PDF sections : Specific pages or sections in program materials - Additional resources : Related content that might be helpful Best Practices \u00b6 Writing Effective Questions \u00b6 \u2705 Good Questions \u00b6 @gutless-assistant What supplements are recommended for Week 1? @gutless-assistant How should I prepare for the elimination phase? @gutless-assistant What are the expected timeline and milestones? \u274c Avoid These \u00b6 @gutless-assistant Help me @gutless-assistant What should I do? @gutless-assistant Tell me everything Tips for Better Results \u00b6 Be Specific : Ask about particular topics, protocols, or concepts Use Keywords : Include relevant terms from the program materials Context Matters : Mention if you're asking about a specific day, phase, or situation Follow Up : Ask clarifying questions if you need more detail Question Examples by Category \u00b6 Nutrition & Diet \u00b6 @gutless-assistant What's the difference between Phase 1 and Phase 2 foods? @gutless-assistant How much water should I drink during Week 1? @gutless-assistant Are there any emergency foods I can eat if I'm struggling? Symptoms & Reactions \u00b6 @gutless-assistant What symptoms are normal during the first week? @gutless-assistant How long do detox symptoms typically last? @gutless-assistant When should I be concerned about a reaction? Protocols & Procedures \u00b6 @gutless-assistant What's the morning routine for Week 1? @gutless-assistant How do I properly do the elimination protocol? @gutless-assistant What should I track during this week? Troubleshooting \u00b6 @gutless-assistant I'm having trouble with [specific issue], what should I do? @gutless-assistant The protocol isn't working as expected, what might be wrong? @gutless-assistant I missed a day, how do I get back on track? Bot Capabilities \u00b6 What the Bot Can Do \u00b6 \u2705 Answer questions about Week 1 content \u2705 Provide video timestamps for specific topics \u2705 Reference relevant PDF materials \u2705 Explain concepts and protocols \u2705 Offer troubleshooting guidance \u2705 Provide context and background information What the Bot Cannot Do \u00b6 \u274c Provide medical advice or diagnoses \u274c Answer questions about content beyond Week 1 \u274c Make personalized recommendations without program context \u274c Replace professional medical consultation \u274c Access your personal health data Response Time \u00b6 Typical Response : 2-5 seconds Complex Questions : 5-10 seconds High Load : May take up to 30 seconds If the bot doesn't respond within 30 seconds, try asking again or check the troubleshooting guide . Privacy & Data \u00b6 What's Stored \u00b6 Your questions and the bot's responses are logged for improvement purposes No personal health information is stored beyond what you explicitly share in questions All data is handled according to privacy best practices What's Not Stored \u00b6 Private Slack messages outside of bot interactions Personal files or attachments Conversation history beyond the current session Getting Help \u00b6 If the Bot Doesn't Understand \u00b6 Try rephrasing your question: Original: \"What about the thing with the gut?\" Better: \"What are the gut healing protocols in Week 1?\" If You Get Unexpected Results \u00b6 Check if your question is about Week 1 content Try being more specific Ask for clarification: \"Can you explain that differently?\" Check the FAQ for common issues Reporting Issues \u00b6 If you encounter problems: Note the exact question you asked Describe what happened vs. what you expected Check the troubleshooting guide Contact support if the issue persists Advanced Usage \u00b6 Multi-Part Questions \u00b6 You can ask follow-up questions in the same conversation: User: @gutless-assistant What foods are eliminated in Week 1? Bot: [Provides list of eliminated foods] User: Why are these foods eliminated? Bot: [Explains the reasoning behind eliminations] Requesting Specific Formats \u00b6 @gutless-assistant Can you give me a bullet-point summary of Week 1 protocols? @gutless-assistant List the top 5 most important things to remember for Week 1 @gutless-assistant What's a step-by-step guide for starting Week 1? Next Steps \u00b6 Troubleshooting Guide FAQ","title":"Usage"},{"location":"usage/#usage-guide","text":"This guide explains how to use the Renesis AI Assistant once it's installed and configured.","title":"Usage Guide"},{"location":"usage/#getting-started","text":"","title":"Getting Started"},{"location":"usage/#inviting-the-bot-to-channels","text":"In your Slack workspace, go to the channel where you want to use the bot Type /invite @gutless-assistant (replace with your bot's name) The bot will join the channel and be ready to answer questions","title":"Inviting the Bot to Channels"},{"location":"usage/#direct-messages","text":"You can also send direct messages to the bot: Click on the bot's name in your Slack workspace Start a direct message conversation Ask your questions directly","title":"Direct Messages"},{"location":"usage/#how-to-ask-questions","text":"","title":"How to Ask Questions"},{"location":"usage/#mentioning-the-bot","text":"In channels, mention the bot to get its attention: @gutless-assistant What are the key principles covered in Week 1?","title":"Mentioning the Bot"},{"location":"usage/#direct-questions","text":"In direct messages, you can ask questions without mentioning: Can you explain the gut health fundamentals from the first week?","title":"Direct Questions"},{"location":"usage/#question-types","text":"The bot can handle various types of questions about Week 1 content:","title":"Question Types"},{"location":"usage/#content-specific-questions","text":"@gutless-assistant What foods should I avoid in Week 1? @gutless-assistant How long should I follow the Week 1 protocol? @gutless-assistant What are the symptoms I might experience?","title":"Content-Specific Questions"},{"location":"usage/#clarification-questions","text":"@gutless-assistant Can you explain more about [specific topic]? @gutless-assistant What did the coach mean when they said [quote]? @gutless-assistant I didn't understand the part about [topic]","title":"Clarification Questions"},{"location":"usage/#reference-questions","text":"@gutless-assistant Where can I find the Week 1 meal plan? @gutless-assistant What time in the video was this discussed? @gutless-assistant Is there a PDF with this information?","title":"Reference Questions"},{"location":"usage/#understanding-bot-responses","text":"","title":"Understanding Bot Responses"},{"location":"usage/#response-format","text":"The bot provides structured responses that include: Direct Answer : A clear, concise answer to your question Source References : Links to relevant video timestamps or PDF sections Additional Context : Related information that might be helpful","title":"Response Format"},{"location":"usage/#example-response","text":"\ud83e\udd16 **Renesis AI Assistant** Based on the Week 1 content, here are the key foods to avoid: \u2022 Processed foods and refined sugars \u2022 Gluten-containing grains \u2022 Dairy products (except for specific exceptions mentioned) \u2022 Inflammatory oils like vegetable and seed oils \ud83d\udcf9 **Video Reference**: [Week 1 Coaching Call - 15:30-18:45](link-to-video) \ud83d\udcc4 **PDF Reference**: Week 1 Food Guide, Page 3 \ud83d\udca1 **Additional Info**: The coach also mentioned that individual tolerance may vary, so pay attention to your body's responses.","title":"Example Response"},{"location":"usage/#source-links","text":"The bot provides clickable links that take you directly to: - Video timestamps : Exact moments in coaching calls where topics are discussed - PDF sections : Specific pages or sections in program materials - Additional resources : Related content that might be helpful","title":"Source Links"},{"location":"usage/#best-practices","text":"","title":"Best Practices"},{"location":"usage/#writing-effective-questions","text":"","title":"Writing Effective Questions"},{"location":"usage/#good-questions","text":"@gutless-assistant What supplements are recommended for Week 1? @gutless-assistant How should I prepare for the elimination phase? @gutless-assistant What are the expected timeline and milestones?","title":"\u2705 Good Questions"},{"location":"usage/#avoid-these","text":"@gutless-assistant Help me @gutless-assistant What should I do? @gutless-assistant Tell me everything","title":"\u274c Avoid These"},{"location":"usage/#tips-for-better-results","text":"Be Specific : Ask about particular topics, protocols, or concepts Use Keywords : Include relevant terms from the program materials Context Matters : Mention if you're asking about a specific day, phase, or situation Follow Up : Ask clarifying questions if you need more detail","title":"Tips for Better Results"},{"location":"usage/#question-examples-by-category","text":"","title":"Question Examples by Category"},{"location":"usage/#nutrition-diet","text":"@gutless-assistant What's the difference between Phase 1 and Phase 2 foods? @gutless-assistant How much water should I drink during Week 1? @gutless-assistant Are there any emergency foods I can eat if I'm struggling?","title":"Nutrition &amp; Diet"},{"location":"usage/#symptoms-reactions","text":"@gutless-assistant What symptoms are normal during the first week? @gutless-assistant How long do detox symptoms typically last? @gutless-assistant When should I be concerned about a reaction?","title":"Symptoms &amp; Reactions"},{"location":"usage/#protocols-procedures","text":"@gutless-assistant What's the morning routine for Week 1? @gutless-assistant How do I properly do the elimination protocol? @gutless-assistant What should I track during this week?","title":"Protocols &amp; Procedures"},{"location":"usage/#troubleshooting","text":"@gutless-assistant I'm having trouble with [specific issue], what should I do? @gutless-assistant The protocol isn't working as expected, what might be wrong? @gutless-assistant I missed a day, how do I get back on track?","title":"Troubleshooting"},{"location":"usage/#bot-capabilities","text":"","title":"Bot Capabilities"},{"location":"usage/#what-the-bot-can-do","text":"\u2705 Answer questions about Week 1 content \u2705 Provide video timestamps for specific topics \u2705 Reference relevant PDF materials \u2705 Explain concepts and protocols \u2705 Offer troubleshooting guidance \u2705 Provide context and background information","title":"What the Bot Can Do"},{"location":"usage/#what-the-bot-cannot-do","text":"\u274c Provide medical advice or diagnoses \u274c Answer questions about content beyond Week 1 \u274c Make personalized recommendations without program context \u274c Replace professional medical consultation \u274c Access your personal health data","title":"What the Bot Cannot Do"},{"location":"usage/#response-time","text":"Typical Response : 2-5 seconds Complex Questions : 5-10 seconds High Load : May take up to 30 seconds If the bot doesn't respond within 30 seconds, try asking again or check the troubleshooting guide .","title":"Response Time"},{"location":"usage/#privacy-data","text":"","title":"Privacy &amp; Data"},{"location":"usage/#whats-stored","text":"Your questions and the bot's responses are logged for improvement purposes No personal health information is stored beyond what you explicitly share in questions All data is handled according to privacy best practices","title":"What's Stored"},{"location":"usage/#whats-not-stored","text":"Private Slack messages outside of bot interactions Personal files or attachments Conversation history beyond the current session","title":"What's Not Stored"},{"location":"usage/#getting-help","text":"","title":"Getting Help"},{"location":"usage/#if-the-bot-doesnt-understand","text":"Try rephrasing your question: Original: \"What about the thing with the gut?\" Better: \"What are the gut healing protocols in Week 1?\"","title":"If the Bot Doesn't Understand"},{"location":"usage/#if-you-get-unexpected-results","text":"Check if your question is about Week 1 content Try being more specific Ask for clarification: \"Can you explain that differently?\" Check the FAQ for common issues","title":"If You Get Unexpected Results"},{"location":"usage/#reporting-issues","text":"If you encounter problems: Note the exact question you asked Describe what happened vs. what you expected Check the troubleshooting guide Contact support if the issue persists","title":"Reporting Issues"},{"location":"usage/#advanced-usage","text":"","title":"Advanced Usage"},{"location":"usage/#multi-part-questions","text":"You can ask follow-up questions in the same conversation: User: @gutless-assistant What foods are eliminated in Week 1? Bot: [Provides list of eliminated foods] User: Why are these foods eliminated? Bot: [Explains the reasoning behind eliminations]","title":"Multi-Part Questions"},{"location":"usage/#requesting-specific-formats","text":"@gutless-assistant Can you give me a bullet-point summary of Week 1 protocols? @gutless-assistant List the top 5 most important things to remember for Week 1 @gutless-assistant What's a step-by-step guide for starting Week 1?","title":"Requesting Specific Formats"},{"location":"usage/#next-steps","text":"Troubleshooting Guide FAQ","title":"Next Steps"}]}